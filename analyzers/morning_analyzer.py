"""
analyzers/morning_analyzer.py
ì•„ì¹¨ ë¶„ì„ í†µí•© ëª¨ë“ˆ (v12.0 Step 6 ì‹ ê·œ / Step 8 ì™„ì„±)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
[í†µí•© ë‚´ìš© â€” v12.0 Step 6~8]
  â‘  geopolitics_analyzer     â†’ _analyze_geopolitics() ì™„ì „ í¡ìˆ˜
  â‘¡ theme_analyzer           â†’ _analyze_theme()        ë‚´ë¶€ í•¨ìˆ˜ë¡œ í†µí•©
  â‘¢ oracle_analyzer          â†’ _pick_stocks()          ë‚´ë¶€ í•¨ìˆ˜ë¡œ í†µí•© (ëª…ì¹­ ë³€ê²½)
  â‘£ sector_flow_analyzer     â†’ data_collector._build_signals()ë¡œ ì™„ì „ ì´ì „ (Step 8)
                                [ì´ íŒŒì¼ì—ì„œ ì‹ í˜¸7 ìƒì„± ë¡œì§ ì œê±° â€” ARCHITECTURE #9]
  â‘¤ event_impact_analyzer   â†’ _analyze_event_impact()  ë‚´ë¶€ í•¨ìˆ˜ë¡œ í†µí•©
  â‘¥ ai_analyzer.analyze_dart()    â†’ Gemini 2.5 Flash ì¬ì‘ì„±
  â‘¦ ai_analyzer.analyze_closing() â†’ Gemini 2.5 Flash ì¬ì‘ì„±

[signal_analyzer ì²˜ë¦¬ â€” v12.0 Step 8]
  signal_analyzer â†’ data_collector ë‚´ë¶€ë¡œ ì´ì „ (ì´ íŒŒì¼ ì•„ë‹˜)
  data_collector._build_signals() ê°€ ì‹ í˜¸1~8 ìƒì„± + ìºì‹œì— ì €ì¥
  ì´ íŒŒì¼ì€ data_collector ìºì‹œì˜ signals ë¥¼ ë°›ì•„ Gemini ë¶„ì„ë§Œ ìˆ˜í–‰

[analyze() ì‹¤í–‰ ìˆœì„œ]
  â‘  _analyze_geopolitics()        ì§€ì •í•™ ì‚¬ì „ë§¤ì¹­ + Gemini ë³´ì™„
  â‘¡ _analyze_event_impact()       ê¸°ì—…ì´ë²¤íŠ¸ ì‹ í˜¸8 (ì´ë²¤íŠ¸ ì ìˆ˜ ê³„ì‚°)
  â‘¢ prebuilt_signals ìˆ˜ì‹          ì‹ í˜¸1~8 (data_collector ìºì‹œ)
  â‘£ _analyze_dart_with_gemini()   Gemini ê³µì‹œ ë¶„ì„
  â‘¤ _analyze_closing_with_gemini() Gemini í…Œë§ˆ ê·¸ë£¹í•‘ (ì‹ í˜¸4 êµì²´)
  â‘¥ _analyze_theme()              í…Œë§ˆ ì§€ë„ + ì†Œì™¸ë„ ê³„ì‚°
  â‘¦ _pick_stocks()                ì»¨í”Œë£¨ì–¸ìŠ¤ ìŠ¤ì½”ì–´ë§ â†’ ìª½ì§‘ê²Œ í”½

[AI ëª¨ë¸]
  Primary  : gemini-2.5-flash  (google-genai SDK)
  ê¸°ì¡´ Gemma-3-27b-it / gemini-1.5-flash / gemini-2.0-flash ì‚¬ìš© ì¤‘ë‹¨

[PUBLIC API]
  analyze() â€” morning_report.pyê°€ ì´ í•¨ìˆ˜ í•˜ë‚˜ë§Œ í˜¸ì¶œ

[ARCHITECTURE ì˜ì¡´ì„±]
  morning_analyzer â† morning_report.py (ë‹¨ìˆœí™”ëœ í˜¸ì¶œ)
  morning_analyzer â† data_collector ìºì‹œ (signals, score_summary í¬í•¨)
  morning_analyzer â†’ geopolitics_map (utils â€” ì‚¬ì „ ë§¤ì¹­)

[ì ˆëŒ€ ê¸ˆì§€ â€” ARCHITECTURE ì¤€ìˆ˜]
  ì´ íŒŒì¼ì—ì„œ KIS API ì§ì ‘ í˜¸ì¶œ ê¸ˆì§€
  ì´ íŒŒì¼ì—ì„œ í…”ë ˆê·¸ë¨ ë°œì†¡ ê¸ˆì§€
  ì´ íŒŒì¼ì—ì„œ DB ê¸°ë¡ ê¸ˆì§€
  ì´ íŒŒì¼ì—ì„œ ì‹ í˜¸1~8 ìƒì„± ë¡œì§ êµ¬í˜„ ê¸ˆì§€ (data_collector ë‹´ë‹¹)
  ë¶„ì„Â·Gemini í˜¸ì¶œë§Œ ë‹´ë‹¹

[ë³€ê²½ ì´ë ¥]
  v12.0 Step 6: ì‹ ê·œ ìƒì„± (geopolitics/theme/oracle/event_impact í¡ìˆ˜)
  v12.0 Step 8: signal_analyzer â†’ data_collector ì´ì „. analyze() â‘¢ ë¸”ë¡ ìºì‹œ ìˆ˜ì‹ ìœ¼ë¡œ êµì²´
                sector_flow_analyzer ë¡œì§ â†’ data_collector._build_signals()ë¡œ ì™„ì „ ì´ì „
                _analyze_sector_flow() ë¸”ë¡ analyze()ì—ì„œ ì œê±° (dead code ì •ë¦¬)
"""

import json
import re
import statistics
from datetime import datetime, timezone, timedelta
from utils.logger import logger
import config

KST = timezone(timedelta(hours=9))

# â”€â”€ Gemini API ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_GEMINI_MODEL = "gemini-2.5-flash"   # ì§€ì› ëª¨ë¸ (2025 ê¸°ì¤€)

try:
    from google import genai as _genai_mod
    from google.genai import types as _genai_types

    if config.GOOGLE_AI_API_KEY:
        _CLIENT = _genai_mod.Client(api_key=config.GOOGLE_AI_API_KEY)
        logger.info(f"[morning_analyzer] Gemini ({_GEMINI_MODEL}) ì´ˆê¸°í™” ì™„ë£Œ")
    else:
        _CLIENT = None
        logger.warning("[morning_analyzer] GOOGLE_AI_API_KEY ì—†ìŒ â€” Gemini ë¶„ì„ ë¹„í™œì„±")
except ImportError:
    _CLIENT = None
    logger.warning("[morning_analyzer] google-genai íŒ¨í‚¤ì§€ ì—†ìŒ â€” pip install google-genai")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PUBLIC API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def analyze(
    dart_data:        list[dict],
    market_data:      dict,
    news_data:        dict,
    price_data:       dict | None      = None,
    geopolitics_raw:  list[dict] | None = None,  # news_global_rss ìˆ˜ì§‘ ê²°ê³¼
    event_calendar:   list[dict] | None = None,  # event_calendar_collector ê²°ê³¼
    sector_etf_data:  list[dict] | None = None,  # sector_etf_collector ê²°ê³¼
    short_data:       list[dict] | None = None,  # short_interest_collector ê²°ê³¼
    # [v12.0 Step 7] data_collector ì‚¬ì „ ìˆ˜ì§‘ ê²°ê³¼ (ìˆìœ¼ë©´ ì¤‘ë³µ ìˆ˜ì§‘ ìƒëµ)
    closing_strength_result:    list[dict] | None = None,  # ë§ˆê°ê°•ë„ ë°ì´í„°
    volume_surge_result:        list[dict] | None = None,  # ê±°ë˜ëŸ‰ê¸‰ì¦ ë°ì´í„°
    fund_concentration_result:  list[dict] | None = None,  # ìê¸ˆì§‘ì¤‘ ë°ì´í„°
    # [v12.0 Step 8] data_collectorê°€ signal_analyzer ë¡œì§ìœ¼ë¡œ ìƒì„±í•œ ì‹ í˜¸ ëª©ë¡
    prebuilt_signals:     list[dict] | None = None,  # data_collector._build_signals() ê²°ê³¼
    prebuilt_market_summary: dict | None = None,     # ë¯¸êµ­ì¦ì‹œ ìš”ì•½ (data_collector ìºì‹œ)
    prebuilt_commodities:    dict | None = None,     # ì›ìì¬ (data_collector ìºì‹œ)
    prebuilt_volatility:     str  | None = None,     # ë³€ë™ì„± íŒë‹¨ (data_collector ìºì‹œ)
    prebuilt_report_picks:   list | None = None,     # ë¦¬í¬íŠ¸ ì¢…ëª© (data_collector ìºì‹œ)
    prebuilt_policy_summary: list | None = None,     # ì •ì±… ë‰´ìŠ¤ (data_collector ìºì‹œ)
    prebuilt_sector_scores:  dict | None = None,     # ì„¹í„° ì ìˆ˜ (data_collector ìºì‹œ)
    prebuilt_event_scores:   dict | None = None,     # ì´ë²¤íŠ¸ ì ìˆ˜ (data_collector ìºì‹œ)
) -> dict:
    """
    ì•„ì¹¨ë´‡ ì „ì²´ ë¶„ì„ í†µí•© ì‹¤í–‰ (morning_report.pyê°€ ì´ê²ƒë§Œ í˜¸ì¶œ)

    [v12.0 Step 8 ë³€ê²½]
    ì‹ í˜¸1~8 ìƒì„±ì€ data_collector._build_signals()ê°€ ë‹´ë‹¹.
    prebuilt_signals ê°€ None ì´ë©´ signals ë¹ˆ ëª©ë¡ìœ¼ë¡œ ì‹œì‘ (í•˜ìœ„ í˜¸í™˜).
    ì´ í•¨ìˆ˜ëŠ” Gemini ë¶„ì„(ê³µì‹œÂ·ìˆœí™˜ë§¤Â·ì§€ì •í•™)ê³¼ í…Œë§ˆ/í”½ ì¡°í•©ë§Œ ìˆ˜í–‰.

    Args:
        dart_data:           filings.collect() ë°˜í™˜ê°’
        market_data:         market_global.collect() ë°˜í™˜ê°’
        news_data:           news_naver + news_newsapi í†µí•© ê²°ê³¼
        price_data:          price_domestic.collect_daily() ë°˜í™˜ê°’
        geopolitics_raw:     news_global_rss.collect() ë°˜í™˜ê°’
        event_calendar:      event_calendar.collect() ë°˜í™˜ê°’
        sector_etf_data:     sector_etf.collect() ë°˜í™˜ê°’
        short_data:          short_interest.collect() ë°˜í™˜ê°’
        closing_strength_result: ë§ˆê°ê°•ë„ ë°ì´í„°
        volume_surge_result:     ê±°ë˜ëŸ‰ê¸‰ì¦ ë°ì´í„°
        fund_concentration_result: ìê¸ˆì§‘ì¤‘ ë°ì´í„°
        prebuilt_signals:    data_collector._build_signals() ê²°ê³¼ (ì‹ í˜¸1~8)
        prebuilt_*:          data_collector ìºì‹œì˜ íŒŒìƒ ë°ì´í„°

    Returns: dict {
        "ai_dart_results":      list,   # Gemini ê³µì‹œ ë¶„ì„ ê²°ê³¼
        "signals":              list,   # ì‹ í˜¸ 1~8 í†µí•© ëª©ë¡ (ê°•ë„ ë‚´ë¦¼ì°¨ìˆœ)
        "market_summary":       dict,   # ë¯¸êµ­ì¦ì‹œ ìš”ì•½
        "commodities":          dict,   # ì›ìì¬ ë°ì´í„°
        "volatility":           str,    # ë³€ë™ì„± íŒë‹¨
        "report_picks":         list,   # ì¦ê¶Œì‚¬ ë¦¬í¬íŠ¸ ì¢…ëª©
        "policy_summary":       list,   # ì •ì±… ë‰´ìŠ¤ ìš”ì•½
        "theme_result":         dict,   # ìˆœí™˜ë§¤ í…Œë§ˆ ì§€ë„
        "oracle_result":        dict,   # ìª½ì§‘ê²Œ ì¢…ëª© í”½ (_pick_stocks)
        "sector_scores":        dict,   # ì„¹í„° ë°©í–¥ì„± ì ìˆ˜
        "event_scores":         dict,   # ê¸°ì—…ì´ë²¤íŠ¸ ì ìˆ˜
        "geopolitics_analyzed": list,   # ì§€ì •í•™ ë¶„ì„ ê²°ê³¼
    }
    """
    result: dict = {
        "ai_dart_results":      [],
        "signals":              [],
        "market_summary":       {},
        "commodities":          {},
        "volatility":           "íŒë‹¨ë¶ˆê°€",
        "report_picks":         [],
        "policy_summary":       [],
        "theme_result":         {"theme_map": [], "volatility": "íŒë‹¨ë¶ˆê°€", "top_signals": []},
        "oracle_result":        None,
        "sector_scores":        {},
        "event_scores":         {},
        "geopolitics_analyzed": [],
    }

    # â”€â”€ â‘  ì§€ì •í•™ ë¶„ì„ (geopolitics_analyzer í¡ìˆ˜) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if geopolitics_raw:
        try:
            geo_analyzed = _analyze_geopolitics(geopolitics_raw)
            result["geopolitics_analyzed"] = geo_analyzed
            logger.info(f"[morning_analyzer] ì§€ì •í•™ ë¶„ì„ ì™„ë£Œ â€” {len(geo_analyzed)}ê±´")
        except Exception as e:
            logger.warning(f"[morning_analyzer] ì§€ì •í•™ ë¶„ì„ ì‹¤íŒ¨: {e}")

    # â”€â”€ â‘¡ ê¸°ì—… ì´ë²¤íŠ¸ ë¶„ì„ (event_impact_analyzer ë‚´ë¶€ í†µí•©) â”€â”€
    event_impact_signals: list[dict] = []
    if event_calendar and config.EVENT_CALENDAR_ENABLED:
        try:
            event_impact_signals = _analyze_event_impact(event_calendar)
            for ev in event_impact_signals:
                ticker = ev.get("ticker", "")
                if ticker:
                    result["event_scores"][ticker] = max(
                        result["event_scores"].get(ticker, 0), ev.get("strength", 3)
                    )
            logger.info(f"[morning_analyzer] ì´ë²¤íŠ¸ ì‹ í˜¸8 {len(event_impact_signals)}ê±´")
        except Exception as e:
            logger.warning(f"[morning_analyzer] ì´ë²¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {e}")

    # â”€â”€ â‘¢ ì‹ í˜¸ 1~8 â€” data_collector ìºì‹œì—ì„œ ìˆ˜ì‹  (Step 8) â”€â”€â”€â”€
    # signal_analyzer ë¡œì§ì€ data_collector._build_signals()ë¡œ ì´ì „ë¨.
    # prebuilt_signals ê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©. ì—†ìœ¼ë©´ ë¹ˆ ëª©ë¡ (í•˜ìœ„ í˜¸í™˜).
    result["signals"]        = list(prebuilt_signals or [])
    result["market_summary"] = dict(prebuilt_market_summary or
                                    market_data.get("us_market", {}))
    result["commodities"]    = dict(prebuilt_commodities or
                                    market_data.get("commodities", {}))
    result["volatility"]     = prebuilt_volatility or "íŒë‹¨ë¶ˆê°€"
    result["report_picks"]   = list(prebuilt_report_picks or [])
    result["policy_summary"] = list(prebuilt_policy_summary or [])
    if prebuilt_sector_scores:
        result["sector_scores"] = dict(prebuilt_sector_scores)
    if prebuilt_event_scores:
        result["event_scores"]  = dict(prebuilt_event_scores)
    logger.info(f"[morning_analyzer] ì‹ í˜¸ ìˆ˜ì‹  â€” {len(result['signals'])}ê°œ (data_collector ìºì‹œ)")

    # â”€â”€ â‘£ Gemini ê³µì‹œ ë¶„ì„ (ai_analyzer.analyze_dart ëŒ€ì²´) â”€â”€â”€
    if dart_data:
        try:
            ai_dart = _analyze_dart_with_gemini(dart_data)
            result["ai_dart_results"] = ai_dart
            if ai_dart:
                _enrich_signals_with_dart(result["signals"], ai_dart)
                logger.info(f"[morning_analyzer] Gemini ê³µì‹œ ë¶„ì„ {len(ai_dart)}ê±´")
        except Exception as e:
            logger.warning(f"[morning_analyzer] Gemini ê³µì‹œ ë¶„ì„ ì‹¤íŒ¨: {e}")

    # â”€â”€ â‘¤ Gemini ìˆœí™˜ë§¤ í…Œë§ˆ ê·¸ë£¹í•‘ (ai_analyzer.analyze_closing ëŒ€ì²´) â”€
    if price_data:
        try:
            ai_closing = _analyze_closing_with_gemini(price_data)
            if ai_closing:
                non_signal4 = [s for s in result["signals"] if "ì‹ í˜¸4" not in s.get("ë°œí™”ì‹ í˜¸", "")]
                result["signals"] = non_signal4 + ai_closing
                result["signals"].sort(key=lambda x: x["ê°•ë„"], reverse=True)
                logger.info(f"[morning_analyzer] Gemini í…Œë§ˆ ê·¸ë£¹í•‘ {len(ai_closing)}ê°œ (ì‹ í˜¸4 êµì²´)")
        except Exception as e:
            logger.warning(f"[morning_analyzer] Gemini í…Œë§ˆ ê·¸ë£¹í•‘ ì‹¤íŒ¨: {e}")

    # â”€â”€ â‘¥ í…Œë§ˆ ë¶„ì„ (theme_analyzer ë‚´ë¶€ í†µí•©) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    try:
        price_by_name = price_data.get("by_name", {}) if price_data else {}
        result["theme_result"] = _analyze_theme(
            signal_result = {"signals": result["signals"]},
            price_data    = price_by_name,
        )
    except Exception as e:
        logger.warning(f"[morning_analyzer] í…Œë§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")

    # â”€â”€ â‘¦ ìª½ì§‘ê²Œ í”½ ìƒì„± (_pick_stocks â€” oracle_analyzer ë‚´ë¶€ í†µí•©) â”€
    try:
        import utils.watchlist_state as watchlist_state
        market_env_val = watchlist_state.get_market_env() or ""
        result["oracle_result"] = _pick_stocks(
            theme_map        = result["theme_result"].get("theme_map", []),
            price_by_name    = price_data.get("by_name", {}) if price_data else {},
            institutional    = price_data.get("institutional", []) if price_data else [],
            ai_dart_results  = result["ai_dart_results"],
            signals          = result["signals"],
            market_env       = market_env_val,
            sector_scores    = result["sector_scores"],
            event_scores     = result["event_scores"],
            # [v12.0 Step 7] data_collector ì‚¬ì „ ìˆ˜ì§‘ ê²°ê³¼ ì „ë‹¬
            closing_strength = closing_strength_result,
            volume_surge     = volume_surge_result,
            fund_concentration = fund_concentration_result,
        )
    except Exception as e:
        logger.warning(f"[morning_analyzer] ìª½ì§‘ê²Œ í”½ ì‹¤íŒ¨ (ë¹„ì¹˜ëª…ì ): {e}")
        result["oracle_result"] = None

    return result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â‘  ì§€ì •í•™ ë¶„ì„ â€” geopolitics_analyzer ì™„ì „ í¡ìˆ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _analyze_geopolitics(raw_news: list[dict]) -> list[dict]:
    """
    ì§€ì •í•™ ë‰´ìŠ¤ â†’ ì˜í–¥ ì„¹í„° ë§¤í•‘ + Gemini ê²€ì¦.
    (geopolitics_analyzer.analyze() ëŒ€ì²´)

    Step 1: geopolitics_map ì‚¬ì „ ê¸°ë°˜ íŒ¨í„´ ë§¤ì¹­
    Step 2: Gemini 2.5 Flash ë°°ì¹˜ ë¶„ì„ (ë³´ì™„)
    Step 3: ì‹ ë¢°ë„ í•„í„°ë§
    """
    if not raw_news:
        return []

    from utils.geopolitics_map import lookup as map_lookup

    # Step 1: ì‚¬ì „ ë§¤ì¹­
    event_agg: dict[str, dict] = {}
    for article in raw_news:
        text    = article.get("raw_text", "")
        title   = article.get("title", "")
        matches = map_lookup(text + " " + title)
        for match in matches:
            key = match["key"]
            if key not in event_agg:
                event_agg[key] = {"map_entry": match, "articles": [], "hit_count": 0}
            event_agg[key]["articles"].append(article)
            event_agg[key]["hit_count"] += 1

    map_results: list[dict] = []
    for key, agg in event_agg.items():
        entry     = agg["map_entry"]
        hit_count = agg["hit_count"]
        base_conf = entry.get("confidence_base", 0.6)
        confidence = min(base_conf + (hit_count - 1) * 0.05, 0.95)

        articles = sorted(agg["articles"], key=lambda a: a.get("published", ""), reverse=True)
        rep      = articles[0] if articles else {}

        map_results.append({
            "event_type":       key,
            "affected_sectors": entry.get("sectors", []),
            "impact_direction": entry.get("impact", "+"),
            "confidence":       round(confidence, 3),
            "source_url":       rep.get("link", ""),
            "event_summary_kr": rep.get("title", entry.get("description", key)),
        })

    logger.info(f"[morning_analyzer] ì§€ì •í•™ ì‚¬ì „ ë§¤ì¹­: {len(map_results)}ê±´")

    # Step 2: Gemini ë³´ì™„ (AI ì‚¬ìš© ê°€ëŠ¥ ì‹œ)
    results = map_results
    if _CLIENT and map_results:
        try:
            results = _enhance_geopolitics_with_gemini(map_results, raw_news)
        except Exception as e:
            logger.warning(f"[morning_analyzer] ì§€ì •í•™ Gemini ë³´ì™„ ì‹¤íŒ¨: {e}")

    # Step 3: ì‹ ë¢°ë„ í•„í„°ë§
    min_conf = config.GEOPOLITICS_CONFIDENCE_MIN
    filtered = [r for r in results if r.get("confidence", 0) >= min_conf]
    filtered.sort(key=lambda x: x.get("confidence", 0), reverse=True)

    logger.info(f"[morning_analyzer] ì§€ì •í•™ ìµœì¢… {len(filtered)}ê±´ (ì‹ ë¢°ë„â‰¥{min_conf})")
    return filtered


def _enhance_geopolitics_with_gemini(
    map_results: list[dict],
    raw_news:    list[dict],
) -> list[dict]:
    """Geminië¡œ ì§€ì •í•™ ì´ë²¤íŠ¸ ë°°ì¹˜ ë¶„ì„ ë° ì‹ ë¢°ë„ ë³´ì •."""
    news_texts = "\n".join(
        f"{i+1}. [{a.get('source','')}] {a.get('title','')}"
        for i, a in enumerate(raw_news[:10])
    )
    matched_keys = [r["event_type"] for r in map_results]

    prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ ì‹œì¥ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ í•œêµ­ ì£¼ì‹ ì‹œì¥ì— ì˜í–¥ì„ ì¤„ ì§€ì •í•™Â·ì •ì±… ì´ë²¤íŠ¸ë¥¼ ì‹ë³„í•˜ì„¸ìš”.

[ë‰´ìŠ¤ ëª©ë¡]
{news_texts}

[ì´ë¯¸ ê°ì§€ëœ ì´ë²¤íŠ¸]
{matched_keys}

ë‹¤ìŒ í˜•ì‹ì˜ JSON ë°°ì—´ë§Œ ì¶œë ¥ (ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ìŒ):
[
  {{
    "event_type": "ì´ë²¤íŠ¸ ìœ í˜• (í•œêµ­ì–´)",
    "affected_sectors": ["ì„¹í„°1", "ì„¹í„°2"],
    "impact_direction": "+" ë˜ëŠ” "-" ë˜ëŠ” "mixed",
    "confidence": 0.0~1.0,
    "event_summary_kr": "50ì ì´ë‚´ í•œêµ­ì–´ ìš”ì•½"
  }}
]

ê·œì¹™:
- ì´ë¯¸ ê°ì§€ëœ ì´ë²¤íŠ¸ëŠ” ì‹ ë¢°ë„ ì¡°ì • í¬í•¨
- ìƒˆë¡œìš´ ì´ë²¤íŠ¸ë„ ì¶”ê°€
- í•œêµ­ ì£¼ì‹ ì‹œì¥ê³¼ ë¬´ê´€í•œ ì´ë²¤íŠ¸ëŠ” ì œì™¸
- ì„¹í„°ëª…: ì² ê°•/ë¹„ì² ê¸ˆì†, ì‚°ì—…ì¬/ë°©ì‚°, ê¸°ìˆ /ë°˜ë„ì²´, ì—ë„ˆì§€/ì •ìœ , ì†Œì¬/í™”í•™, ë°”ì´ì˜¤/í—¬ìŠ¤ì¼€ì–´, ê¸ˆìœµ, ì¡°ì„ , ë°°í„°ë¦¬, ìë™ì°¨ë¶€í’ˆ"""

    raw = _call_gemini(prompt)

    # JSON ì¶”ì¶œ
    clean = re.sub(r"```(?:json)?", "", raw).replace("```", "").strip()
    match = re.search(r"\[", clean)
    if not match:
        return map_results
    json_str = clean[match.start():]
    end = json_str.rfind("]")
    if end == -1:
        return map_results
    ai_results = json.loads(json_str[:end + 1])

    # ì‚¬ì „ + AI ë³‘í•©
    merged: dict[str, dict] = {r["event_type"]: r for r in map_results}
    for ai in ai_results:
        if not isinstance(ai, dict):
            continue
        etype = ai.get("event_type", "")
        if not etype:
            continue
        if etype in merged:
            exist = merged[etype]
            exist["confidence"] = round(
                min(exist["confidence"] * 0.6 + float(ai.get("confidence", 0)) * 0.4, 0.95), 3
            )
        else:
            merged[etype] = {
                "event_type":       etype,
                "affected_sectors": ai.get("affected_sectors", []),
                "impact_direction": ai.get("impact_direction", "+"),
                "confidence":       round(float(ai.get("confidence", 0.5)), 3),
                "source_url":       "",
                "event_summary_kr": ai.get("event_summary_kr", etype),
            }

    return list(merged.values())


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â‘¡ Gemini ê³µì‹œ ë¶„ì„ â€” ai_analyzer.analyze_dart() ëŒ€ì²´
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _analyze_dart_with_gemini(dart_list: list[dict]) -> list[dict]:
    """
    DART ê³µì‹œ ë¦¬ìŠ¤íŠ¸ â†’ Gemini 2.5 Flashë¡œ í˜¸ì¬/ì•…ì¬ ì ìˆ˜í™”.
    (ai_analyzer.analyze_dart() ëŒ€ì²´)

    Returns:
        [{"ì¢…ëª©ëª…": str, "ì ìˆ˜": int(1~10), "ì´ìœ ": str, "ìƒí•œê°€í™•ë¥ ": str}]
    """
    if not _CLIENT or not dart_list:
        return []

    top   = dart_list[:5]
    items = "\n".join(
        f"{i+1}. [{d['ì¢…ëª©ëª…']}] {d['ê³µì‹œì¢…ë¥˜']} â€” {d['ê³µì‹œì‹œê°']}"
        for i, d in enumerate(top)
    )

    time_ctx = _get_market_time_context()

    prompt = f"""í•œêµ­ ì£¼ì‹ ê³µì‹œ ë¶„ì„ ì „ë¬¸ê°€ë‹¤. ë‹¤ìŒ ê³µì‹œë“¤ì„ ë¶„ì„í•˜ë¼.

## ì‹œê°„ ì»¨í…ìŠ¤íŠ¸
{time_ctx}

## DART ê³µì‹œ ìœ í˜•ë³„ íŒë‹¨ ê¸°ì¤€
- ìˆ˜ì£¼/ê³„ì•½: ë§¤ì¶œ ëŒ€ë¹„ ê·œëª¨ ì¤‘ìš”. ì‹œì´ ëŒ€ë¹„ 10% ì´ìƒì´ë©´ ì ìˆ˜ 7+
- ë°°ë‹¹ê²°ì •: ë‹¨ê¸° ìˆ˜ê¸‰ ê¸ì •, ì„±ì¥ ê¸°ëŒ€ì¹˜ ë‚®ìŒ. ì ìˆ˜ 5~6
- ìì‚¬ì£¼ ì·¨ë“: ë‹¨ê¸° ìˆ˜ê¸‰ ë°©ì–´. ê·œëª¨ ëŒ€ë¹„ ì ìˆ˜ ì¡°ì •
- ìœ ìƒì¦ì: ì£¼ê°€ í¬ì„ â†’ ì•…ì¬. ì ìˆ˜ 1~3
- ëŒ€ê·œëª¨ ë‚´ë¶€ì ë§¤ë„: ê°•í•œ ì•…ì¬ ì‹ í˜¸. ì ìˆ˜ 1~2
- íŠ¹í—ˆ/ê¸°ìˆ ì´ì „: ê¸°ìˆ  ê°€ì¹˜ ì¸ì •. ì ìˆ˜ 6~8

## ê³µì‹œ ëª©ë¡
{items}

JSON ë°°ì—´ë§Œ ì¶œë ¥. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´:
[
  {{"ë²ˆí˜¸": 1, "ì ìˆ˜": 8, "ì´ìœ ": "ëŒ€ê·œëª¨ ìˆ˜ì£¼ë¡œ ë§¤ì¶œ ì„±ì¥ ê¸°ëŒ€", "ìƒí•œê°€í™•ë¥ ": "ë†’ìŒ"}},
  {{"ë²ˆí˜¸": 2, "ì ìˆ˜": 4, "ì´ìœ ": "ë°°ë‹¹ ê²°ì •, ë‹¨ê¸° ìˆ˜ê¸‰ ê¸ì •", "ìƒí•œê°€í™•ë¥ ": "ë‚®ìŒ"}}
]

ê·œì¹™:
- ì ìˆ˜: 1(ê°•í•œì•…ì¬)~10(ê°•í•œí˜¸ì¬), 5ëŠ” ì¤‘ë¦½
- ìƒí•œê°€í™•ë¥ : ë†’ìŒ ë˜ëŠ” ì¤‘ê°„ ë˜ëŠ” ë‚®ìŒ
- ì´ìœ : 20ì ì´ë‚´"""

    try:
        raw  = _call_gemini(prompt)
        data = _extract_json(raw)
        if not isinstance(data, list):
            return []

        results = []
        for item in data:
            idx = int(item.get("ë²ˆí˜¸", 1)) - 1
            if 0 <= idx < len(top):
                results.append({
                    "ì¢…ëª©ëª…":     top[idx]["ì¢…ëª©ëª…"],
                    "ì ìˆ˜":       int(item.get("ì ìˆ˜", 5)),
                    "ì´ìœ ":       item.get("ì´ìœ ", ""),
                    "ìƒí•œê°€í™•ë¥ ": item.get("ìƒí•œê°€í™•ë¥ ", "ë‚®ìŒ"),
                })
        return results

    except Exception as e:
        logger.warning(f"[morning_analyzer] Gemini ê³µì‹œ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return []


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â‘¢ Gemini í…Œë§ˆ ê·¸ë£¹í•‘ â€” ai_analyzer.analyze_closing() ëŒ€ì²´
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _analyze_closing_with_gemini(price_result: dict) -> list[dict]:
    """
    ì „ë‚  ìƒí•œê°€+ê¸‰ë“± â†’ Gemini 2.5 Flashë¡œ í…Œë§ˆë³„ ê·¸ë£¹í•‘ + ì†Œì™¸ì£¼ ì‹ë³„.
    (ai_analyzer.analyze_closing() ëŒ€ì²´)

    Returns:
        list[dict] â€” signal_result["signals"] í˜•ì‹ (í…Œë§ˆ ì‹ í˜¸ ëª©ë¡)
    """
    if not _CLIENT:
        return []

    upper   = price_result.get("upper_limit", [])
    gainers = price_result.get("top_gainers", [])
    all_stocks = price_result.get("by_name", {})

    if not upper and not gainers:
        return []

    # 5%â†‘ ì¢…ëª© + ë“±ë½ë¥  (ëŒ€ì¥ì£¼ ì„ ì •ìš©)
    all_movers = {
        name: info["ë“±ë½ë¥ "]
        for name, info in all_stocks.items()
        if isinstance(info.get("ë“±ë½ë¥ "), float) and info["ë“±ë½ë¥ "] >= 5.0
    }

    upper_str = "\n".join(
        f"  - {s['ì¢…ëª©ëª…']} +{s['ë“±ë½ë¥ ']:.1f}% ({s['ì‹œì¥']})" for s in upper[:15]
    )
    gainers_str = "\n".join(
        f"  - {s['ì¢…ëª©ëª…']} +{s['ë“±ë½ë¥ ']:.1f}% ({s['ì‹œì¥']})" for s in gainers[:15]
    )
    movers_sorted = sorted(all_movers.items(), key=lambda x: -x[1])
    movers_str = "\n".join(
        f"  {name}: +{rate:.1f}%"
        for name, rate in movers_sorted[:50]
    )

    time_ctx = _get_market_time_context()

    prompt = f"""í•œêµ­ ì£¼ì‹ì‹œì¥ ì „ë‚  ë§ˆê° ë°ì´í„° ë¶„ì„ â€” ë‚´ì¼ ìˆœí™˜ë§¤ ì§€ë„ ì‘ì„±

## ì‹œê°„ ì»¨í…ìŠ¤íŠ¸
{time_ctx}

=== ì „ë‚  ìƒí•œê°€ ===
{upper_str if upper_str else 'ì—†ìŒ'}

=== ì „ë‚  ê¸‰ë“±(7%â†‘) ===
{gainers_str if gainers_str else 'ì—†ìŒ'}

=== ì „ë‚  5%â†‘ ì „ì²´ (ë“±ë½ë¥  ë†’ì€ ìˆœ) ===
{movers_str if movers_str else 'ì—†ìŒ'}

**ëª©í‘œ**: ê°™ì€ í…Œë§ˆ(ì„¹í„°)ë¼ë¦¬ ë¬¶ê³  ëŒ€ì¥ì£¼ì™€ ì†Œì™¸ì£¼ë¥¼ ì‹ë³„í•˜ë¼.

**í•µì‹¬ ê·œì¹™**:
1. í…Œë§ˆëª…: ì‹¤ì œ ì‹œì¥ í†µìš© ëª…ì¹­ (ë°”ì´ì˜¤ì‹ ì•½, ì „ì„ êµ¬ë¦¬, AIë°˜ë„ì²´, ë°©ì‚°, 2ì°¨ì „ì§€ ë“±)
2. ê´€ë ¨ì¢…ëª©[0] = í•´ë‹¹ í…Œë§ˆì—ì„œ ë“±ë½ë¥ ì´ ê°€ì¥ ë†’ì€ ì¢…ëª© (ëŒ€ì¥ì£¼)
3. ê´€ë ¨ì¢…ëª©[1],[2]... = ê°™ì€ í…Œë§ˆì¸ë° ë“±ë½ë¥ ì´ ë‚®ì€ ì†Œì™¸ì£¼
4. ì†Œì™¸ì£¼ëŠ” ë°˜ë“œì‹œ ìœ„ 5%â†‘ ì „ì²´ ëª©ë¡ì— ìˆëŠ” ì¢…ëª©ë§Œ í¬í•¨
5. í…Œë§ˆê°€ ë‹¤ë¥¸ ì¢…ëª©ë¼ë¦¬ ì–µì§€ë¡œ ë¬¶ì§€ ë§ ê²ƒ
6. ìµœëŒ€ 5ê°œ í…Œë§ˆ, ê°•ë„ ë†’ì€ ìˆœ
7. JSON ë°°ì—´ë§Œ ì¶œë ¥, ì„¤ëª… ì—†ì´

[
  {{
    "í…Œë§ˆëª…": "ë°”ì´ì˜¤ì‹ ì•½",
    "ê°•ë„": 5,
    "ê´€ë ¨ì¢…ëª©": ["ì—ì´í”„ë¡œì  ", "ë‚˜ë…¸ì—”í…", "ì¼€ìŠ¤í”¼ì˜¨"],
    "ai_memo": "ì—ì´í”„ë¡œì   ì£¼ë„ ìƒí•œê°€, ë‚˜ë…¸ì—”í… ì†Œì™¸"
  }}
]"""

    try:
        raw    = _call_gemini(prompt)
        parsed = _extract_json(raw)
        if not isinstance(parsed, list):
            return []

        signals = []
        for item in parsed:
            ê´€ë ¨ì¢…ëª© = item.get("ê´€ë ¨ì¢…ëª©", [])
            if not ê´€ë ¨ì¢…ëª©:
                continue
            ê°•ë„ = max(1, min(5, int(item.get("ê°•ë„", 3))))
            signals.append({
                "í…Œë§ˆëª…":   item.get("í…Œë§ˆëª…", "ê¸°íƒ€"),
                "ë°œí™”ì‹ í˜¸": f"ì‹ í˜¸4(AI): {item.get('ai_memo', '')[:50]}",
                "ê°•ë„":     ê°•ë„,
                "ì‹ ë¢°ë„":   "Gemini",
                "ë°œí™”ë‹¨ê³„": "ì˜¤ëŠ˜",
                "ìƒíƒœ":     "ì‹ ê·œ",
                "ê´€ë ¨ì¢…ëª©": ê´€ë ¨ì¢…ëª©,
                "ai_memo":  item.get("ai_memo", ""),
            })

        signals.sort(key=lambda x: x["ê°•ë„"], reverse=True)
        return signals

    except Exception as e:
        logger.warning(f"[morning_analyzer] Gemini í…Œë§ˆ ê·¸ë£¹í•‘ ì‹¤íŒ¨: {e}")
        return []


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â‘£ í…Œë§ˆ ë¶„ì„ â€” theme_analyzer ë‚´ë¶€ í†µí•©
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _analyze_theme(signal_result: dict, price_data: dict) -> dict:
    """
    í…Œë§ˆ ê·¸ë£¹í•‘ + ìˆœí™˜ë§¤ ì†Œì™¸ë„ ê³„ì‚°.
    (theme_analyzer.analyze() ë‚´ë¶€ í†µí•©)
    """
    signals    = signal_result.get("signals", [])
    volatility = signal_result.get("volatility", "íŒë‹¨ë¶ˆê°€")

    theme_map = _build_theme_map(signals, price_data)

    return {
        "theme_map":   theme_map,
        "volatility":  volatility,
        "top_signals": signals[:3],
    }


def _build_theme_map(signals: list[dict], price_data: dict) -> list[dict]:
    themes = []
    for signal in signals:
        ê´€ë ¨ì¢…ëª© = signal.get("ê´€ë ¨ì¢…ëª©", [])
        if not ê´€ë ¨ì¢…ëª©:
            continue

        ì¢…ëª©ë“¤ = []
        ëŒ€ì¥ë“±ë½ë¥  = None

        for i, ì¢…ëª©ëª… in enumerate(ê´€ë ¨ì¢…ëª©):
            ë“±ë½ë¥  = price_data.get(ì¢…ëª©ëª…, {}).get("ë“±ë½ë¥ ", "N/A") if price_data else "N/A"

            if i == 0:
                ëŒ€ì¥ë“±ë½ë¥  = ë“±ë½ë¥ 
                í¬ì§€ì…˜ = "ì´ë¯¸ê³¼ì—´" if (isinstance(ë“±ë½ë¥ , float) and ë“±ë½ë¥  >= 15) else "ëŒ€ì¥"
            else:
                if isinstance(ë“±ë½ë¥ , float) and isinstance(ëŒ€ì¥ë“±ë½ë¥ , float):
                    ì†Œì™¸ë„ = round(ëŒ€ì¥ë“±ë½ë¥  - ë“±ë½ë¥ , 1)
                    if ì†Œì™¸ë„ >= 20:
                        í¬ì§€ì…˜ = "ì˜¤ëŠ˜â˜…"
                    elif ì†Œì™¸ë„ >= 10:
                        í¬ì§€ì…˜ = "ë‚´ì¼"
                    else:
                        í¬ì§€ì…˜ = "ëª¨ë‹ˆí„°"
                else:
                    ì†Œì™¸ë„ = "N/A"
                    í¬ì§€ì…˜ = "ëª¨ë‹ˆí„°"

                ì¢…ëª©ë“¤.append({
                    "ì¢…ëª©ëª…": ì¢…ëª©ëª…,
                    "ë“±ë½ë¥ ": ë“±ë½ë¥ ,
                    "ì†Œì™¸ë„": ì†Œì™¸ë„,
                    "í¬ì§€ì…˜": í¬ì§€ì…˜,
                })

        themes.append({
            "í…Œë§ˆëª…":     signal["í…Œë§ˆëª…"],
            "ëŒ€ì¥ì£¼":     ê´€ë ¨ì¢…ëª©[0] if ê´€ë ¨ì¢…ëª© else "N/A",
            "ëŒ€ì¥ë“±ë½ë¥ ": ëŒ€ì¥ë“±ë½ë¥  if ëŒ€ì¥ë“±ë½ë¥  is not None else "N/A",
            "ì¢…ëª©ë“¤":     ì¢…ëª©ë“¤,
            "ìƒíƒœ":       signal["ìƒíƒœ"],
            "ë°œí™”ì‹ í˜¸":   signal["ë°œí™”ì‹ í˜¸"],
        })

    return themes


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â‘¤ ê¸°ì—… ì´ë²¤íŠ¸ ë¶„ì„ â€” event_impact_analyzer ë‚´ë¶€ í†µí•©
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_EVENT_CONFIG = {
    "ì‹¤ì ë°œí‘œ": {"direction": "+", "base_strength": 4,
                "reason_template": "{corp} ì‹¤ì ë°œí‘œ D-{days} â€” ê¸°ê´€ ì‚¬ì „ í¬ì§€ì…”ë‹ ì˜ˆìƒ",
                "lookahead_days": 2},
    "IR":       {"direction": "+", "base_strength": 3,
                "reason_template": "{corp} ê¸°ì—…ì„¤ëª…íšŒ D-{days} â€” ê¸°ê´€/ì™¸ì¸ ê´€ì‹¬ ì„ í–‰ ìœ ì…",
                "lookahead_days": 2},
    "ì£¼ì£¼ì´íšŒ": {"direction": "mixed", "base_strength": 3,
                "reason_template": "{corp} ì£¼ì£¼ì´íšŒ D-{days} â€” ì†Œì•¡ì£¼ì£¼ ì´ìŠˆÂ·ë°°ë‹¹ í™•ì • ì˜ˆìƒ",
                "lookahead_days": 5},
    "ë°°ë‹¹":     {"direction": "+", "base_strength": 4,
                "reason_template": "{corp} ë°°ë‹¹ ê³µì‹œ D-{days} â€” ë°°ë‹¹ë½ ì „ ë§¤ìˆ˜ ìˆ˜ê¸‰ ì¦ê°€",
                "lookahead_days": 3},
}


def _analyze_event_impact(events: list[dict]) -> list[dict]:
    """ê¸°ì—… ì´ë²¤íŠ¸ â†’ ì‹ í˜¸8. (event_impact_analyzer.analyze() ë‚´ë¶€ í†µí•©)"""
    if not events:
        return []
    signals = []
    for ev in events:
        sig = _process_event(ev)
        if sig is not None:
            signals.append(sig)
    signals.sort(key=lambda x: (-x["strength"], x["days_until"]))
    logger.info(f"[morning_analyzer] ì´ë²¤íŠ¸ ì‹ í˜¸8 {len(signals)}ê±´")
    return signals


def _process_event(ev: dict) -> dict | None:
    event_type = ev.get("event_type", "")
    days_until = ev.get("days_until", -1)
    corp_name  = ev.get("corp_name", "")
    ticker     = ev.get("ticker", "")
    cfg = _EVENT_CONFIG.get(event_type)
    if cfg is None:
        return None
    if days_until < 0 or days_until > cfg["lookahead_days"]:
        return None
    strength = cfg["base_strength"]
    if days_until <= 1:
        strength = min(5, strength + 1)
    return {
        "event_type":       event_type,
        "corp_name":        corp_name,
        "ticker":           ticker,
        "event_date":       ev.get("event_date", ""),
        "days_until":       days_until,
        "impact_direction": cfg["direction"],
        "strength":         strength,
        "reason":           cfg["reason_template"].format(corp=corp_name, days=days_until),
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â‘¥ ìª½ì§‘ê²Œ í”½ â€” oracle_analyzer ë‚´ë¶€ í†µí•© (_pick_stocks)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_TARGET_PCT = {"ì˜¤ëŠ˜â˜…": 0.15, "ë‚´ì¼": 0.12, "ëª¨ë‹ˆí„°": 0.10, "ëŒ€ì¥": 0.08, "": 0.10}
_STOP_PCT   = -0.07
_RR_THRESHOLD = {"ê°•ì„¸ì¥": 1.2, "ì•½ì„¸ì¥": 2.0, "ì•½ì„¸ì¥/íš¡ë³´": 2.0, "íš¡ë³´": 2.0, "": 1.5}


def _pick_stocks(
    theme_map:       list[dict],
    price_by_name:   dict,
    institutional:   list[dict],
    ai_dart_results: list[dict],
    signals:         list[dict],
    market_env:      str  = "",
    closing_strength: list | None = None,
    volume_surge:      list | None = None,
    fund_concentration: list | None = None,
    sector_scores:   dict | None = None,
    event_scores:    dict | None = None,
) -> dict:
    """
    ì»¨í”Œë£¨ì–¸ìŠ¤ ìŠ¤ì½”ì–´ë§ â†’ ë‚´ì¼ ì£¼ë„ í…Œë§ˆ + ì¢…ëª© í”½.
    (oracle_analyzer.analyze() ë‚´ë¶€ í†µí•© ì™„ë£Œ â€” ëª…ì¹­: oracle_analyzer â†’ _pick_stocks)
    """
    _empty = {
        "picks": [], "top_themes": [],
        "market_env": market_env,
        "rr_threshold": _RR_THRESHOLD.get(market_env, 1.5),
        "one_line": f"[{market_env or 'ì¥ì„¸ë¯¸ì •'}] ë¶„ì„ ë°ì´í„° ë¶€ì¡±",
        "has_data": False,
    }

    if not isinstance(price_by_name, dict):
        logger.warning("[morning_analyzer._pick_stocks] price_by_nameì´ dictê°€ ì•„ë‹˜")
        return _empty

    if not theme_map and not signals:
        return _empty

    try:
        # ë³´ì¡° ë°ì´í„° ì¸ë±ì‹±
        inst_map   = {s.get("ì¢…ëª©ëª…", ""): s for s in institutional if s.get("ì¢…ëª©ëª…")}
        dart_map   = {r.get("ì¢…ëª©ëª…", ""): r for r in ai_dart_results if r.get("ì¢…ëª©ëª…")}
        cs_set     = {s.get("ì¢…ëª©ì½”ë“œ", "") for s in (closing_strength or []) if s.get("ì¢…ëª©ì½”ë“œ")}
        vf_set     = {s.get("ì¢…ëª©ì½”ë“œ", "") for s in (volume_surge or [])      if s.get("ì¢…ëª©ì½”ë“œ")}
        fi_set     = {s.get("ì¢…ëª©ì½”ë“œ", "") for s in (fund_concentration or [])      if s.get("ì¢…ëª©ì½”ë“œ")}
        sector_map = sector_scores or {}
        event_map  = event_scores  or {}

        # ì‹ í˜¸ ë§µ
        sig_map: dict[str, dict] = {}
        for s in signals:
            theme = s.get("í…Œë§ˆëª…", "")
            if theme:
                sig_map[theme] = s
            for name in s.get("ê´€ë ¨ì¢…ëª©", []):
                if name:
                    sig_map[name] = s

        rr_threshold = _RR_THRESHOLD.get(market_env, 1.5)

        # í…Œë§ˆ ìŠ¤ì½”ì–´ë§
        scored = []
        for theme in theme_map:
            score, factors = _score_theme_internal(
                theme, price_by_name, inst_map, dart_map,
                cs_set, vf_set, fi_set, sig_map, sector_map, event_map,
            )
            if score > 0:
                scored.append({
                    "theme": theme.get("í…Œë§ˆëª…", ""),
                    "score": score, "factors": factors,
                    "leader": theme.get("ëŒ€ì¥ì£¼", ""),
                    "leader_change": theme.get("ëŒ€ì¥ë“±ë½ë¥ ", 0.0),
                    "_theme_obj": theme,
                })
        scored.sort(key=lambda x: x["score"], reverse=True)
        top_themes = [{k: v for k, v in t.items() if k != "_theme_obj"} for t in scored[:3]]

        # í”½ ì¶”ì¶œ
        picks = []
        seen  = set()
        for t_entry in scored[:3]:
            t_obj  = t_entry["_theme_obj"]
            t_name = t_entry["theme"]
            for stock in t_obj.get("ì¢…ëª©ë“¤", []):
                name = stock.get("ì¢…ëª©ëª…", "")
                if not name or name in seen:
                    continue
                info  = price_by_name.get(name, {})
                code  = info.get("ì¢…ëª©ì½”ë“œ", "")
                price = info.get("ì¢…ê°€", 0) or info.get("í˜„ì¬ê°€", 0)
                if price <= 0:
                    continue
                pos_type = stock.get("í¬ì§€ì…˜", "")
                pick = _build_pick_entry(
                    name, code, t_name, price, pos_type, t_entry["score"],
                    inst_map, dart_map, cs_set, vf_set, fi_set, rr_threshold,
                )
                if pick:
                    seen.add(name)
                    picks.append(pick)
                if len(picks) >= 5:
                    break
            if len(picks) >= 5:
                break

        for i, p in enumerate(picks, 1):
            p["rank"] = i

        one_line = (
            f"[{market_env or 'ì¥ì„¸ë¯¸ì •'}] ì¡°ê±´ ì¶©ì¡± í”½ ì—†ìŒ (R/R {rr_threshold:.1f}x ë¯¸ë‹¬)"
            if not picks
            else (
                f"[{market_env or 'ì¥ì„¸ë¯¸ì •'}] ì£¼ë„í…Œë§ˆ: "
                + " Â· ".join(t["theme"] for t in top_themes[:2])
                + f" | ìµœì„ í”½: {picks[0]['name']} "
                + f"(ì§„ì…{picks[0]['entry_price']:,} â†’ ëª©í‘œ{picks[0]['target_price']:,} "
                + f"/ ì†ì ˆ{picks[0]['stop_price']:,}  R/R {picks[0]['rr_ratio']:.1f})"
            )
        )

        return {
            "picks": picks, "top_themes": top_themes,
            "market_env": market_env, "rr_threshold": rr_threshold,
            "one_line": one_line, "has_data": bool(picks),
        }

    except Exception as e:
        logger.warning(f"[morning_analyzer._pick_stocks] ì‹¤íŒ¨: {e}", exc_info=True)
        return _empty


def _score_theme_internal(
    theme, price_by_name, inst_map, dart_map, cs_set, vf_set, fi_set,
    sig_map, sector_scores, event_scores,
) -> tuple[int, list[str]]:
    """ì»¨í”Œë£¨ì–¸ìŠ¤ ì ìˆ˜ ê³„ì‚°. (_pick_stocks ë‚´ë¶€ í•¨ìˆ˜ â€” oracle_analyzer._score_theme ì™„ì „ í†µí•©)"""
    score   = 0
    factors = []
    stocks  = theme.get("ì¢…ëª©ë“¤", [])
    t_name  = theme.get("í…Œë§ˆëª…", "")

    # ê¸°ê´€/ì™¸ì¸ ìˆ˜ê¸‰ (ìµœëŒ€ 30ì )
    inst_c = sum(1 for st in stocks if inst_map.get(st.get("ì¢…ëª©ëª…",""),{}).get("ê¸°ê´€ìˆœë§¤ìˆ˜",0) > 0)
    frgn_c = sum(1 for st in stocks if inst_map.get(st.get("ì¢…ëª©ëª…",""),{}).get("ì™¸êµ­ì¸ìˆœë§¤ìˆ˜",0) > 0)
    sm = inst_c + frgn_c
    if sm >= 6:   score += 30; factors.append(f"ê¸°ê´€/ì™¸ì¸ {sm}ì¢…ëª© â˜…â˜…â˜…")
    elif sm >= 4: score += 22; factors.append(f"ê¸°ê´€/ì™¸ì¸ {sm}ì¢…ëª© â˜…â˜…")
    elif sm >= 2: score += 14; factors.append(f"ê¸°ê´€/ì™¸ì¸ {sm}ì¢…ëª© â˜…")
    elif sm >= 1: score += 7;  factors.append(f"ê¸°ê´€/ì™¸ì¸ {sm}ì¢…ëª©")

    # ì†Œì™¸ë„ ì—ë„ˆì§€ (ìµœëŒ€ 25ì )
    total_ì†Œì™¸ = sum(
        st.get("ì†Œì™¸ë„", 0.0) for st in stocks if isinstance(st.get("ì†Œì™¸ë„"), (int, float))
    )
    avg_ì†Œì™¸ = total_ì†Œì™¸ / len(stocks) if stocks else 0
    if avg_ì†Œì™¸ >= 5.0:   score += 25; factors.append(f"ì†Œì™¸ë„ {avg_ì†Œì™¸:.1f} â˜…â˜…â˜…")
    elif avg_ì†Œì™¸ >= 3.0: score += 18; factors.append(f"ì†Œì™¸ë„ {avg_ì†Œì™¸:.1f} â˜…â˜…")
    elif avg_ì†Œì™¸ >= 1.5: score += 10; factors.append(f"ì†Œì™¸ë„ {avg_ì†Œì™¸:.1f} â˜…")
    elif avg_ì†Œì™¸ > 0:    score += 5;  factors.append(f"ì†Œì™¸ë„ {avg_ì†Œì™¸:.1f}")

    # ë§ˆê°ê°•ë„ (ìµœëŒ€ 20ì )
    cs_c = sum(
        1 for st in stocks
        if price_by_name.get(st.get("ì¢…ëª©ëª…",""),{}).get("ì¢…ëª©ì½”ë“œ","") in cs_set
    )
    if cs_c >= 3:   score += 20; factors.append(f"ë§ˆê°ê°•ë„ {cs_c}ì¢…ëª© â˜…â˜…â˜…")
    elif cs_c == 2: score += 14; factors.append(f"ë§ˆê°ê°•ë„ {cs_c}ì¢…ëª© â˜…â˜…")
    elif cs_c == 1: score += 8;  factors.append(f"ë§ˆê°ê°•ë„ {cs_c}ì¢…ëª© â˜…")

    # ê³µì‹œ AI ì ìˆ˜ (ìµœëŒ€ 15ì )
    max_dart = max(
        (dart_map.get(st.get("ì¢…ëª©ëª…",""),{}).get("ì ìˆ˜",0) for st in stocks), default=0
    )
    if max_dart >= 9:   score += 15; factors.append(f"ê³µì‹œAI {max_dart}/10 â˜…â˜…â˜…")
    elif max_dart >= 7: score += 10; factors.append(f"ê³µì‹œAI {max_dart}/10 â˜…â˜…")
    elif max_dart >= 5: score += 5;  factors.append(f"ê³µì‹œAI {max_dart}/10 â˜…")

    # ìê¸ˆì§‘ì¤‘/ê±°ë˜ëŸ‰ê¸‰ì¦ ë³´ì¡° (ìµœëŒ€ 10ì )
    fi_c = sum(
        1 for st in stocks
        if price_by_name.get(st.get("ì¢…ëª©ëª…",""),{}).get("ì¢…ëª©ì½”ë“œ","") in fi_set
    )
    vf_c = sum(
        1 for st in stocks
        if price_by_name.get(st.get("ì¢…ëª©ëª…",""),{}).get("ì¢…ëª©ì½”ë“œ","") in vf_set
    )
    if fi_c >= 2:   score += 7; factors.append(f"ìê¸ˆì§‘ì¤‘ {fi_c}ì¢…ëª©")
    elif fi_c == 1: score += 4; factors.append(f"ìê¸ˆì§‘ì¤‘ {fi_c}ì¢…ëª©")
    if vf_c >= 1:   score += 3; factors.append(f"ê±°ë˜ëŸ‰ê¸‰ì¦ {vf_c}ì¢…ëª©")

    # ì‹ í˜¸ ê°•ë„ ë³´ë„ˆìŠ¤ (ìµœëŒ€ 5ì )
    sig = sig_map.get(t_name)
    if sig:
        sig_s = sig.get("ê°•ë„", 0)
        if sig_s >= 5:   score += 5; factors.append("ì‹ í˜¸ê°•ë„ â˜…â˜…â˜…â˜…â˜…")
        elif sig_s >= 4: score += 4; factors.append("ì‹ í˜¸ê°•ë„ â˜…â˜…â˜…â˜…")
        elif sig_s >= 3: score += 2; factors.append("ì‹ í˜¸ê°•ë„ â˜…â˜…â˜…")

    # ì² ê°•/ë°©ì‚° ë¶€ìŠ¤íŒ… (+20)
    BOOST_THEMES = {"ì² ê°•/ë¹„ì² ê¸ˆì†", "ì² ê°•", "ë°©ì‚°", "ì‚°ì—…ì¬/ë°©ì‚°", "ì—ë„ˆì§€ì†”ë£¨ì…˜", "ìë™ì°¨ë¶€í’ˆ"}
    if t_name in BOOST_THEMES and t_name in sig_map:
        score += 20
        factors.append("ğŸŒ ì§€ì •í•™/ì² ê°•ETF ë¶€ìŠ¤íŒ… +20")

    # ì„¹í„° ìˆ˜ê¸‰ ë³´ë„ˆìŠ¤ (+10~+20)
    if sector_scores:
        sf = sector_scores.get(t_name, 0)
        if sf >= 30:   score += 20; factors.append("ğŸ“Š ì„¹í„°ETF+ê³µë§¤ë„ ìˆ˜ê¸‰ +20")
        elif sf >= 15: score += 10; factors.append("ğŸ“Š ì„¹í„°ETF ì´ìƒ +10")

    return score, factors


def _build_pick_entry(
    name, ticker, theme, entry_price, position_type,
    theme_score, inst_map, dart_map, cs_set, vf_set, fi_set, rr_threshold,
) -> dict | None:
    target_pct  = _TARGET_PCT.get(position_type, _TARGET_PCT[""])
    target_price = round(entry_price * (1 + target_pct))
    stop_price   = round(entry_price * (1 + _STOP_PCT))

    ret  = target_price - entry_price
    loss = entry_price  - stop_price
    if loss <= 0:
        return None

    rr_ratio = round(ret / loss, 1)
    if rr_ratio < rr_threshold:
        return None

    badges = []
    m = inst_map.get(name, {})
    if m.get("ê¸°ê´€ìˆœë§¤ìˆ˜", 0) > 0 and m.get("ì™¸êµ­ì¸ìˆœë§¤ìˆ˜", 0) > 0:
        badges.append("ê¸°ê´€/ì™¸ì¸â†‘")
    elif m.get("ê¸°ê´€ìˆœë§¤ìˆ˜", 0) > 0:
        badges.append("ê¸°ê´€â†‘")
    elif m.get("ì™¸êµ­ì¸ìˆœë§¤ìˆ˜", 0) > 0:
        badges.append("ì™¸ì¸â†‘")

    if ticker in cs_set: badges.append("ë§ˆê°ê°•ë„â†‘")
    if ticker in vf_set: badges.append("ê±°ë˜ëŸ‰ê¸‰ì¦")
    if ticker in fi_set: badges.append("ìê¸ˆì§‘ì¤‘â†‘")

    dart = dart_map.get(name, {})
    if dart.get("ì ìˆ˜", 0) >= 7:
        badges.append(f"ê³µì‹œAI {dart['ì ìˆ˜']}/10")

    return {
        "rank": 0, "ticker": ticker, "name": name, "theme": theme,
        "entry_price": entry_price, "target_price": target_price, "stop_price": stop_price,
        "target_pct":  round(target_pct * 100, 1),
        "stop_pct":    round(_STOP_PCT * 100, 1),
        "rr_ratio":    rr_ratio,
        "score":       theme_score,
        "badges":      badges,
        "position_type": position_type,
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ê³µí†µ ìœ í‹¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _get_market_time_context() -> str:
    """í˜„ì¬ KST ì‹œê° ê¸°ì¤€ ì¥ì¤‘/ë§ˆê°í›„ ì»¨í…ìŠ¤íŠ¸."""
    now   = datetime.now(KST)
    open_ = now.replace(hour=9,  minute=0,  second=0, microsecond=0)
    close = now.replace(hour=15, minute=20, second=0, microsecond=0)
    if open_ <= now <= close:
        return (
            f"í˜„ì¬ ì‹œê°: {now.strftime('%H:%M')} KST (ì¥ì¤‘)\n"
            "âš ï¸ ì¥ì¤‘ ë°ì´í„° ì£¼ì˜: ì˜¤ëŠ˜ ê±°ë˜ëŸ‰Â·ìº”ë“¤ì€ ë¯¸ì™„ì„± í˜•ì„± ì¤‘.\n"
            "  - ì „ì¼ ë˜ëŠ” ìµœê·¼ í™•ì • ë°ì´í„°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„ì„í•  ê²ƒ"
        )
    return (
        f"í˜„ì¬ ì‹œê°: {now.strftime('%H:%M')} KST (ë§ˆê° í›„)\n"
        "âœ… ë‹¹ì¼ ë°ì´í„° í™•ì •: ê±°ë˜ëŸ‰Â·ìº”ë“¤Â·ë“±ë½ë¥  ëª¨ë‘ ì‹ ë¢° ê°€ëŠ¥."
    )


def _call_gemini(prompt: str) -> str:
    """Gemini 2.5 Flash API í˜¸ì¶œ."""
    if not _CLIENT:
        raise RuntimeError("Gemini í´ë¼ì´ì–¸íŠ¸ ë¯¸ì´ˆê¸°í™”")
    response = _CLIENT.models.generate_content(
        model   = _GEMINI_MODEL,
        contents= prompt,
        config  = _genai_types.GenerateContentConfig(
            temperature      = 0.2,
            max_output_tokens= 1500,
        ),
    )
    return response.text


def _extract_json(raw: str):
    """AI ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ íœìŠ¤ ì œê±° í¬í•¨)."""
    cleaned = re.sub(r"```(?:json)?", "", raw).replace("```", "").strip()
    match   = re.search(r"[\[{]", cleaned)
    if not match:
        raise ValueError(f"JSON ì—†ìŒ: {cleaned[:80]}")
    json_str = cleaned[match.start():]
    end = json_str.rfind("]") if json_str.startswith("[") else json_str.rfind("}")
    if end == -1:
        raise ValueError("JSON ì¢…ë£Œ í† í° ì—†ìŒ")
    json_str = json_str[:end + 1]
    try:
        return json.loads(json_str)
    except json.JSONDecodeError:
        # ê°œë³„ ê°ì²´ ë³µêµ¬ ì‹œë„
        results = []
        for m in re.finditer(r"\{[^{}]+\}", json_str):
            try:
                results.append(json.loads(m.group()))
            except Exception:
                continue
        if results:
            return results
        raise


def _enrich_signals_with_dart(signals: list[dict], ai_results: list[dict]) -> None:
    """AI ê³µì‹œ ë¶„ì„ ê²°ê³¼ë¡œ ì‹ í˜¸ ê°•ë„ ë³´ì • (in-place)."""
    ai_map = {r["ì¢…ëª©ëª…"]: r for r in ai_results}
    for signal in signals:
        ê´€ë ¨ì¢…ëª© = signal.get("ê´€ë ¨ì¢…ëª©", [])
        if not ê´€ë ¨ì¢…ëª©:
            continue
        ai = ai_map.get(ê´€ë ¨ì¢…ëª©[0], {})
        if ai.get("ì ìˆ˜", 0) >= 8:
            signal["ê°•ë„"] = min(5, signal.get("ê°•ë„", 3) + 1)
            signal["ai_ë©”ëª¨"] = f"AI: {ai['ì´ìœ ']} ({ai['ìƒí•œê°€í™•ë¥ ']})"

