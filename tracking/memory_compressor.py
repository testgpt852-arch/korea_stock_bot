"""
tracking/memory_compressor.py
[v6.0 5ë²ˆ/P1 ì‹ ê·œ] trading_journal 3ê³„ì¸µ ê¸°ì–µ ì••ì¶• ë°°ì¹˜

Prism CompressionManager ê²½ëŸ‰í™” ì´ì‹ (ë¹„ë™ê¸° MCP ëŒ€ì‹  ë™ê¸° Gemma ì§ì ‘ í˜¸ì¶œ)

[ì—­í• ]
trading_journal í…Œì´ë¸”ì˜ ì˜¤ë˜ëœ í•­ëª©ì„ ê³„ì¸µì ìœ¼ë¡œ ì••ì¶•í•´
AI í”„ë¡¬í”„íŠ¸ í† í° ì¦ê°€ ë¬¸ì œë¥¼ ë°©ì§€í•˜ê³  ì¥ê¸° ìš´ì˜ ì„±ëŠ¥ì„ ìœ ì§€.

[ì••ì¶• ì „ëµ]
  Layer 1 (0~7ì¼):  ì›ë¬¸ ì „ì²´ ë³´ì¡´ (ê¸°ë³¸ compression_layer=1)
  Layer 2 (8~30ì¼): AIê°€ ìƒí™©ë¶„ì„+íŒë‹¨í‰ê°€+êµí›ˆì„ í•œ ë¬¸ë‹¨ìœ¼ë¡œ ìš”ì•½
                    â†’ summary_text ì €ì¥, ìƒì„¸ JSON í•„ë“œ ì••ì¶•
  Layer 3 (31ì¼+):  í•µì‹¬ ì¸ì‚¬ì´íŠ¸ í•œ ì¤„ë§Œ (one_line_summary ìš°ì„  í™œìš©)
                    â†’ summary_text ìµœì†Œí™”, ìƒì„¸ í•„ë“œ ì´ˆê¸°í™”

[í† í° ì ˆê° íš¨ê³¼]
  Layer 1: ~200ì/í•­ëª© (ì›ë¬¸ ìƒì„¸)
  Layer 2: ~80ì/í•­ëª© (AI ìš”ì•½)
  Layer 3: ~30ì/í•­ëª© (í•µì‹¬ í•œ ì¤„)

[ì‹¤í–‰ ì‹œì ]
  main.py ë§¤ì£¼ ì¼ìš”ì¼ 03:30 â†’ run_compression() ë™ê¸° í˜¸ì¶œ

[ARCHITECTURE ì˜ì¡´ì„±]
memory_compressor â†’ tracking/db_schema    (get_conn)
memory_compressor â† main.py              (run_compression í˜¸ì¶œ)

[ì ˆëŒ€ ê¸ˆì§€ ê·œì¹™]
ì´ íŒŒì¼ì€ DB ì½ê¸° + ì••ì¶• UPDATEë§Œ ë‹´ë‹¹.
í…”ë ˆê·¸ë¨ ë°œì†¡Â·KIS API í˜¸ì¶œÂ·ë§¤ìˆ˜ ë¡œì§ ì ˆëŒ€ ê¸ˆì§€.
ëª¨ë“  í•¨ìˆ˜ëŠ” ë™ê¸°(sync) â€” main.pyì—ì„œ run_in_executor ê²½ìœ  í˜¸ì¶œ.
"""

from __future__ import annotations

import json
import re
from datetime import datetime, timezone, timedelta
from utils.logger import logger
import tracking.db_schema as db_schema
import config

KST = timezone(timedelta(hours=9))

# Google AI SDK (ai_analyzer, trading_journalê³¼ ë™ì¼ íŒ¨í„´)
try:
    from google import genai
    from google.genai import types as _gtypes
    if config.GOOGLE_AI_API_KEY:
        _CLIENT = genai.Client(api_key=config.GOOGLE_AI_API_KEY)
        logger.info("[memory_compressor] AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (í´ë°± ëª¨ë¸ ì ìš©)")
    else:
        _CLIENT = None
except Exception:
    _CLIENT = None


# â”€â”€ ê³µê°œ API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# [v7.0 Priority3] KOSPI ë ˆë²¨ ë²”ìœ„ êµ¬ê°„ í¬ê¸° (200í¬ì¸íŠ¸ ë‹¨ìœ„)
_KOSPI_BUCKET_SIZE = 200


def update_index_stats() -> dict:
    """
    [v7.0 Priority3] KOSPI/KOSDAQ ì§€ìˆ˜ ë ˆë²¨ë³„ ë§¤ë§¤ ìŠ¹ë¥  í†µê³„ ì§‘ê³„ ë°°ì¹˜.

    Prism memory_compressor_agentì˜ 'KOSPI ì‹¬ë¦¬ì  ì§€ì§€/ì €í•­ì„ , ë³€ê³¡ì  êµ¬ê°„ë³„ ìŠ¹ë¥ ' ê¸°ëŠ¥ êµ¬í˜„.
    â†’ 'KOSPI 2400~2600 ì§„ì… ì‹œ ìŠ¹ë¥  72%' ê°™ì€ í†µê³„ë¥¼ ìë™ ì¶”ì¶œ.

    [ë™ì‘]
    trading_history í…Œì´ë¸”ì—ì„œ ì²­ì‚°ëœ ëª¨ë“  ê±°ë˜ë¥¼ ì½ì–´
    buy_market_context (ë§¤ìˆ˜ ë‹¹ì‹œ KOSPI ë ˆë²¨) ê¸°ì¤€ìœ¼ë¡œ ë ˆë²¨ë³„ ìŠ¹ë¥ ì„ ì§‘ê³„.
    â†’ kospi_index_stats í…Œì´ë¸”ì— UPSERT.

    buy_market_context ê°€ ì—†ëŠ” ê±°ë˜ëŠ” ê±´ë„ˆëœ€ (í•˜ìœ„ í˜¸í™˜).

    [í˜¸ì¶œ ì‹œì ]
    run_compression() ì—ì„œ ìë™ í˜¸ì¶œ (ë§¤ì£¼ ì¼ìš”ì¼ 03:30).

    Returns:
        {
          "buckets_updated": int,  # ì—…ë°ì´íŠ¸ëœ ë ˆë²¨ êµ¬ê°„ ìˆ˜
          "trades_analyzed": int,  # ë¶„ì„ëœ ê±°ë˜ ìˆ˜
        }
    """
    conn = db_schema.get_conn()
    try:
        c = conn.cursor()
        # trading_historyì—ì„œ ì²­ì‚°ëœ ê±°ë˜ + ë§¤ìˆ˜ ë‹¹ì‹œ KOSPI ë ˆë²¨ ì¡°íšŒ
        # buy_market_context ì»¬ëŸ¼ì´ ì—†ëŠ” êµ¬ë²„ì „ DBëŠ” graceful ì²˜ë¦¬
        try:
            c.execute("""
                SELECT profit_rate, buy_market_context
                FROM trading_history
                WHERE sell_time IS NOT NULL
                  AND buy_market_context IS NOT NULL
                  AND buy_market_context != ''
            """)
            rows = c.fetchall()
        except Exception:
            # buy_market_context ì»¬ëŸ¼ ì—†ìŒ â†’ í†µê³„ ì§‘ê³„ ë¶ˆê°€
            logger.info("[compressor] kospi_index_stats: buy_market_context ì»¬ëŸ¼ ì—†ìŒ â€” ê±´ë„ˆëœ€")
            return {"buckets_updated": 0, "trades_analyzed": 0}
    finally:
        conn.close()

    if not rows:
        logger.info("[compressor] kospi_index_stats: ë¶„ì„ ê°€ëŠ¥í•œ ê±°ë˜ ì—†ìŒ")
        return {"buckets_updated": 0, "trades_analyzed": 0}

    # {kospi_range: {"wins": int, "total": int, "profits": list[float]}}
    buckets: dict[str, dict] = {}
    trades_analyzed = 0

    for profit_rate, buy_ctx in rows:
        kospi_level = _extract_kospi_level(buy_ctx)
        if kospi_level is None:
            continue

        bucket_key  = _get_kospi_bucket(kospi_level)
        bucket_low  = (kospi_level // _KOSPI_BUCKET_SIZE) * _KOSPI_BUCKET_SIZE
        bucket_high = bucket_low + _KOSPI_BUCKET_SIZE
        kospi_range = f"{bucket_low}~{bucket_high}"

        if kospi_range not in buckets:
            buckets[kospi_range] = {
                "kospi_level": bucket_low + _KOSPI_BUCKET_SIZE // 2,
                "wins": 0, "total": 0, "profits": []
            }

        buckets[kospi_range]["total"] += 1
        if profit_rate is not None and profit_rate > 0:
            buckets[kospi_range]["wins"] += 1
        if profit_rate is not None:
            buckets[kospi_range]["profits"].append(profit_rate)
        trades_analyzed += 1

    # kospi_index_stats í…Œì´ë¸” UPSERT
    buckets_updated = 0
    now_kst = datetime.now(KST).isoformat(timespec="seconds")
    today_str = datetime.now(KST).strftime("%Y-%m-%d")

    for kospi_range, data in buckets.items():
        total   = data["total"]
        wins    = data["wins"]
        profits = data["profits"]
        win_rate = round(wins / total * 100, 1) if total > 0 else 0.0
        avg_profit = round(sum(profits) / len(profits), 2) if profits else 0.0

        conn2 = db_schema.get_conn()
        try:
            c2 = conn2.cursor()
            c2.execute("""
                INSERT INTO kospi_index_stats
                    (trade_date, kospi_level, kospi_range,
                     win_count, total_count, win_rate, avg_profit_rate, last_updated)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ON CONFLICT(kospi_range) DO UPDATE SET
                    trade_date      = excluded.trade_date,
                    win_count       = excluded.win_count,
                    total_count     = excluded.total_count,
                    win_rate        = excluded.win_rate,
                    avg_profit_rate = excluded.avg_profit_rate,
                    last_updated    = excluded.last_updated
            """, (
                today_str,
                data["kospi_level"],
                kospi_range,
                wins, total, win_rate, avg_profit,
                now_kst,
            ))
            conn2.commit()
            buckets_updated += 1
        except Exception as e:
            logger.warning(f"[compressor] kospi_index_stats UPSERT ì‹¤íŒ¨ ({kospi_range}): {e}")
        finally:
            conn2.close()

    logger.info(
        f"[compressor] KOSPI ì§€ìˆ˜ ë ˆë²¨ í†µê³„ ì—…ë°ì´íŠ¸ ì™„ë£Œ â€” "
        f"{buckets_updated}ê°œ êµ¬ê°„ / {trades_analyzed}ê±´ ë¶„ì„"
    )
    return {"buckets_updated": buckets_updated, "trades_analyzed": trades_analyzed}


def get_index_context(current_kospi: float | None = None) -> str:
    """
    [v7.0 Priority3] í˜„ì¬ KOSPI ë ˆë²¨ ê¸°ë°˜ ê³¼ê±° ìŠ¹ë¥  ì»¨í…ìŠ¤íŠ¸ ë°˜í™˜.
    ai_context.build_spike_context()ì—ì„œ AI í”„ë¡¬í”„íŠ¸ ì£¼ì…ìš©ìœ¼ë¡œ í˜¸ì¶œ.

    current_kospiê°€ Noneì´ë©´ ì „ì²´ ë ˆë²¨ Top3 (ê±°ë˜ ìˆ˜ ë§ì€ ìˆœ) ë°˜í™˜.
    current_kospiê°€ ìˆìœ¼ë©´ í•´ë‹¹ ë ˆë²¨ êµ¬ê°„ + ì¸ì ‘ êµ¬ê°„ ìŠ¹ë¥  ë°˜í™˜.

    Returns:
        AI í”„ë¡¬í”„íŠ¸ ì£¼ì…ìš© ë¬¸ìì—´ (ë°ì´í„° ì—†ìœ¼ë©´ "")
    """
    conn = db_schema.get_conn()
    try:
        c = conn.cursor()
        try:
            if current_kospi is not None:
                # í˜„ì¬ ë ˆë²¨ê³¼ ì¸ì ‘ Â±2 êµ¬ê°„ ì¡°íšŒ
                bucket_low  = (int(current_kospi) // _KOSPI_BUCKET_SIZE) * _KOSPI_BUCKET_SIZE
                nearby_lows = [
                    bucket_low - _KOSPI_BUCKET_SIZE * 2,
                    bucket_low - _KOSPI_BUCKET_SIZE,
                    bucket_low,
                    bucket_low + _KOSPI_BUCKET_SIZE,
                    bucket_low + _KOSPI_BUCKET_SIZE * 2,
                ]
                placeholders = ",".join("?" * len(nearby_lows))
                nearby_ranges = [
                    f"{low}~{low + _KOSPI_BUCKET_SIZE}" for low in nearby_lows
                ]
                c.execute(f"""
                    SELECT kospi_range, win_rate, avg_profit_rate, total_count
                    FROM kospi_index_stats
                    WHERE kospi_range IN ({placeholders})
                      AND total_count >= 3
                    ORDER BY kospi_level ASC
                """, nearby_ranges)
            else:
                # ì „ì²´ì—ì„œ ê±°ë˜ ìˆ˜ ë§ì€ Top3
                c.execute("""
                    SELECT kospi_range, win_rate, avg_profit_rate, total_count
                    FROM kospi_index_stats
                    WHERE total_count >= 3
                    ORDER BY total_count DESC
                    LIMIT 3
                """)

            rows = c.fetchall()
        except Exception:
            return ""
    finally:
        conn.close()

    if not rows:
        return ""

    lines = ["ğŸ“Š KOSPI ë ˆë²¨ë³„ ê³¼ê±° ìŠ¹ë¥ :"]
    for kospi_range, win_rate, avg_profit, total in rows:
        lines.append(
            f"  {kospi_range}: ìŠ¹ë¥  {win_rate:.0f}%  í‰ê· ìˆ˜ìµ {avg_profit:+.1f}%  (n={total})"
        )
    return "\n".join(lines)


def _extract_kospi_level(buy_market_context: str) -> int | None:
    """
    buy_market_context ë¬¸ìì—´ì—ì„œ KOSPI ì§€ìˆ˜ê°’ ì¶”ì¶œ.
    ì˜ˆ: "ê°•ì„¸ì¥ KOSPI2547" â†’ 2547
        "KOSPI:2547.3" â†’ 2547
        "íš¡ë³´ kospi=2100" â†’ 2100

    Returns:
        KOSPI ì •ìˆ˜ê°’ / ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ None
    """
    if not buy_market_context:
        return None
    # ìˆ«ì 4ìë¦¬ íŒ¨í„´ (KOSPIëŠ” ë³´í†µ 1000~5000)
    matches = re.findall(r"[Kk][Oo][Ss][Pp][Ii][:\s=]?\s*(\d{4,5}(?:\.\d+)?)", buy_market_context)
    if matches:
        try:
            return int(float(matches[0]))
        except ValueError:
            pass
    # fallback: 4~5ìë¦¬ ìˆ«ì ì¶”ì¶œ
    numbers = re.findall(r"\b(\d{4,5})\b", buy_market_context)
    for n in numbers:
        val = int(n)
        if 500 <= val <= 10000:  # KOSPI ìœ íš¨ ë²”ìœ„
            return val
    return None


def _get_kospi_bucket(kospi_level: int) -> str:
    """
    KOSPI ë ˆë²¨ì„ _KOSPI_BUCKET_SIZE ë‹¨ìœ„ êµ¬ê°„ ë¬¸ìì—´ë¡œ ë³€í™˜.
    ì˜ˆ: 2547 â†’ "2400~2600" (bucket_size=200)
    """
    bucket_low  = (kospi_level // _KOSPI_BUCKET_SIZE) * _KOSPI_BUCKET_SIZE
    bucket_high = bucket_low + _KOSPI_BUCKET_SIZE
    return f"{bucket_low}~{bucket_high}"


def run_compression() -> dict:
    """
    3ê³„ì¸µ ê¸°ì–µ ì••ì¶• ë°°ì¹˜ ì‹¤í–‰.
    main.py ë§¤ì£¼ ì¼ìš”ì¼ 03:30ì—ì„œë§Œ í˜¸ì¶œ.

    Returns:
        {
          "compressed_l1": int,  # Layer1 â†’ Layer2 ì••ì¶• ê±´ìˆ˜
          "compressed_l2": int,  # Layer2 â†’ Layer3 ì••ì¶• ê±´ìˆ˜
          "cleaned":        int,  # Layer3 90ì¼ ì´ìƒ ì •ë¦¬ ê±´ìˆ˜
          "skipped":        int,  # AI ì—†ì–´ì„œ ê±´ë„ˆëœ€
        }
    """
    if not config.MEMORY_COMPRESS_ENABLED:
        logger.info("[compressor] ê¸°ì–µ ì••ì¶• ë¹„í™œì„± (MEMORY_COMPRESS_ENABLED=false)")
        return {"compressed_l1": 0, "compressed_l2": 0, "cleaned": 0, "skipped": 0}

    layer1_cutoff = (
        datetime.now(KST) - timedelta(days=config.MEMORY_COMPRESS_LAYER1_DAYS)
    ).strftime("%Y-%m-%d")

    layer2_cutoff = (
        datetime.now(KST) - timedelta(days=config.MEMORY_COMPRESS_LAYER2_DAYS)
    ).strftime("%Y-%m-%d")

    archive_cutoff = (
        datetime.now(KST) - timedelta(days=90)
    ).strftime("%Y-%m-%d")

    logger.info(
        f"[compressor] ê¸°ì–µ ì••ì¶• ì‹œì‘ â€” "
        f"Layer1â†’2 ê¸°ì¤€: {layer1_cutoff} / "
        f"Layer2â†’3 ê¸°ì¤€: {layer2_cutoff}"
    )

    result = {"compressed_l1": 0, "compressed_l2": 0, "cleaned": 0, "skipped": 0}

    # Step 1: Layer1 â†’ Layer2 (7~30ì¼ í•­ëª© AI ìš”ì•½)
    result["compressed_l1"], result["skipped"] = _compress_layer1_to_2(layer1_cutoff)

    # Step 2: Layer2 â†’ Layer3 (30ì¼+ í•­ëª© í•µì‹¬ë§Œ ë³´ì¡´)
    result["compressed_l2"] += _compress_layer2_to_3(layer2_cutoff)

    # Step 3: Layer3 90ì¼+ í•­ëª© ì •ë¦¬ (summary_textë§Œ ë‚¨ê¸°ê³  ìƒì„¸ ì´ˆê¸°í™”)
    result["cleaned"] = _clean_old_layer3(archive_cutoff)

    # Step 4: [v7.0 Priority3] KOSPI ì§€ìˆ˜ ë ˆë²¨ë³„ ìŠ¹ë¥  í†µê³„ ì—…ë°ì´íŠ¸
    index_result = update_index_stats()
    result["index_buckets_updated"] = index_result.get("buckets_updated", 0)
    result["index_trades_analyzed"] = index_result.get("trades_analyzed", 0)

    logger.info(
        f"[compressor] ê¸°ì–µ ì••ì¶• ì™„ë£Œ â€” "
        f"Layer1â†’2: {result['compressed_l1']}ê±´ / "
        f"Layer2â†’3: {result['compressed_l2']}ê±´ / "
        f"ì •ë¦¬: {result['cleaned']}ê±´ / "
        f"AI ì—†ì–´ ìŠ¤í‚µ: {result['skipped']}ê±´"
    )
    return result


# â”€â”€ ë‚´ë¶€ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _compress_layer1_to_2(cutoff_date: str) -> tuple[int, int]:
    """
    Layer 1 í•­ëª© ì¤‘ cutoff_dateë³´ë‹¤ ì˜¤ë˜ëœ ê²ƒì„ Layer 2ë¡œ ì••ì¶•.
    AIê°€ situation_analysis + judgment_evaluation + lessonsë¥¼ í•œ ë¬¸ë‹¨ìœ¼ë¡œ ìš”ì•½.
    AI ì—†ìœ¼ë©´ rule-based ìš”ì•½ ì‚¬ìš© (ë¹„ì¹˜ëª…ì ).

    Returns:
        (ì••ì¶• ê±´ìˆ˜, AI ì—†ì–´ ìŠ¤í‚µëœ ê±´ìˆ˜)
    """
    conn = db_schema.get_conn()
    try:
        c = conn.cursor()
        c.execute("""
            SELECT id, ticker, name, profit_rate, close_reason,
                   situation_analysis, judgment_evaluation, lessons,
                   one_line_summary, created_at
            FROM trading_journal
            WHERE compression_layer = 1
              AND DATE(created_at) < ?
            ORDER BY created_at ASC
        """, (cutoff_date,))
        rows = c.fetchall()
    except Exception as e:
        logger.warning(f"[compressor] Layer1 ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return 0, 0
    finally:
        conn.close()

    if not rows:
        logger.info("[compressor] Layer1â†’2 ì••ì¶• ëŒ€ìƒ ì—†ìŒ")
        return 0, 0

    compressed = 0
    skipped = 0
    now_kst = datetime.now(KST).isoformat(timespec="seconds")

    for row in rows:
        (jid, ticker, name, profit_rate, close_reason,
         raw_situation, raw_judgment, raw_lessons,
         one_line_summary, created_at) = row

        # AI ìš”ì•½ ì‹œë„
        summary_text = _ai_summarize_to_layer2(
            ticker=ticker, name=name,
            profit_rate=profit_rate, close_reason=close_reason,
            raw_situation=raw_situation, raw_judgment=raw_judgment,
            raw_lessons=raw_lessons,
            one_line_summary=one_line_summary,
        )

        if not summary_text:
            # AI ì—†ìœ¼ë©´ rule-based ìš”ì•½
            summary_text = _rule_based_summary(
                profit_rate, close_reason, raw_lessons, one_line_summary
            )
            if not _CLIENT:
                skipped += 1

        if not summary_text:
            continue

        conn2 = db_schema.get_conn()
        try:
            c2 = conn2.cursor()
            c2.execute("""
                UPDATE trading_journal
                SET compression_layer = 2,
                    summary_text = ?,
                    compressed_at = ?
                WHERE id = ?
            """, (summary_text, now_kst, jid))
            conn2.commit()
            compressed += 1
        except Exception as e:
            logger.warning(f"[compressor] Layer1â†’2 UPDATE ì‹¤íŒ¨ (id={jid}): {e}")
        finally:
            conn2.close()

    logger.info(f"[compressor] Layer1â†’2 ì••ì¶• ì™„ë£Œ: {compressed}ê±´ / ìŠ¤í‚µ: {skipped}ê±´")
    return compressed, skipped


def _compress_layer2_to_3(cutoff_date: str) -> int:
    """
    Layer 2 í•­ëª© ì¤‘ cutoff_dateë³´ë‹¤ ì˜¤ë˜ëœ ê²ƒì„ Layer 3ìœ¼ë¡œ ì••ì¶•.
    summary_textë¥¼ 30ì ì´ë‚´ë¡œ ë‹¨ì¶• + ìƒì„¸ JSON í•„ë“œ ì´ˆê¸°í™”.
    AI ì—†ì´ë„ ë™ì‘ (ë‹¨ìˆœ truncate).
    """
    conn = db_schema.get_conn()
    try:
        c = conn.cursor()
        c.execute("""
            SELECT id, summary_text, one_line_summary
            FROM trading_journal
            WHERE compression_layer = 2
              AND DATE(created_at) < ?
        """, (cutoff_date,))
        rows = c.fetchall()
    except Exception as e:
        logger.warning(f"[compressor] Layer2 ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return 0
    finally:
        conn.close()

    if not rows:
        return 0

    compressed = 0
    now_kst = datetime.now(KST).isoformat(timespec="seconds")

    for jid, summary_text, one_line_summary in rows:
        # Layer 3: ê°€ì¥ ì§§ì€ í•µì‹¬ í…ìŠ¤íŠ¸ë§Œ ìœ ì§€
        core = one_line_summary or summary_text or ""
        core_short = core[:50] if core else ""

        conn2 = db_schema.get_conn()
        try:
            c2 = conn2.cursor()
            c2.execute("""
                UPDATE trading_journal
                SET compression_layer  = 3,
                    summary_text       = ?,
                    compressed_at      = ?,
                    situation_analysis = '{}',
                    judgment_evaluation = '{}',
                    lessons            = '[]'
                WHERE id = ?
            """, (core_short, now_kst, jid))
            conn2.commit()
            compressed += 1
        except Exception as e:
            logger.warning(f"[compressor] Layer2â†’3 UPDATE ì‹¤íŒ¨ (id={jid}): {e}")
        finally:
            conn2.close()

    logger.info(f"[compressor] Layer2â†’3 ì••ì¶• ì™„ë£Œ: {compressed}ê±´")
    return compressed


def _clean_old_layer3(cutoff_date: str) -> int:
    """
    Layer 3 í•­ëª© ì¤‘ 90ì¼ ì´ìƒ ëœ ê²ƒì€ pattern_tagsì™€ one_line_summaryë§Œ ë‚¨ê¸°ê³ 
    ë‚˜ë¨¸ì§€ í…ìŠ¤íŠ¸ í•„ë“œ ì´ˆê¸°í™”. DB í¬ê¸° ë¬´í•œ ì¦ê°€ ë°©ì§€.
    """
    conn = db_schema.get_conn()
    try:
        c = conn.cursor()
        c.execute("""
            UPDATE trading_journal
            SET summary_text = SUBSTR(COALESCE(summary_text, one_line_summary, ''), 1, 30),
                situation_analysis = '{}',
                judgment_evaluation = '{}'
            WHERE compression_layer = 3
              AND DATE(created_at) < ?
        """, (cutoff_date,))
        cleaned = c.rowcount
        conn.commit()
    except Exception as e:
        logger.warning(f"[compressor] Layer3 ì •ë¦¬ ì‹¤íŒ¨: {e}")
        cleaned = 0
    finally:
        conn.close()

    if cleaned > 0:
        logger.info(f"[compressor] Layer3 ì˜¤ë˜ëœ í•­ëª© ì •ë¦¬: {cleaned}ê±´")
    return cleaned


def _ai_summarize_to_layer2(
    ticker: str, name: str,
    profit_rate: float, close_reason: str,
    raw_situation: str, raw_judgment: str, raw_lessons: str,
    one_line_summary: str,
) -> str:
    """
    Gemma AIë¡œ ê±°ë˜ ì¼ì§€ ìƒì„¸ ë‚´ìš©ì„ í•œ ë¬¸ë‹¨(80ì ì´ë‚´)ìœ¼ë¡œ ìš”ì•½.
    API ì—†ê±°ë‚˜ ì‹¤íŒ¨ ì‹œ "" ë°˜í™˜ (í˜¸ì¶œë¶€ì—ì„œ rule-based fallback).
    """
    if not _CLIENT:
        return ""

    # ì›ë³¸ ë°ì´í„° íŒŒì‹±
    try:
        situation = json.loads(raw_situation or "{}")
        judgment  = json.loads(raw_judgment or "{}")
        lessons   = json.loads(raw_lessons or "[]")
    except Exception:
        situation, judgment, lessons = {}, {}, []

    buy_ctx  = situation.get("buy_context_summary", "")
    sell_ctx = situation.get("sell_context_summary", "")
    buy_q    = judgment.get("buy_quality", "")
    sell_q   = judgment.get("sell_quality", "")

    lesson_str = ""
    if lessons and isinstance(lessons, list):
        first = lessons[0] if lessons else {}
        if isinstance(first, dict):
            lesson_str = first.get("action", "")

    prompt = f"""ë‹¤ìŒ ê±°ë˜ ë³µê¸°ë¥¼ 80ì ì´ë‚´ í•œ ë¬¸ì¥ìœ¼ë¡œ ì••ì¶• ìš”ì•½í•˜ì„¸ìš”. í•µì‹¬ êµí›ˆ ì¤‘ì‹¬. ì„¤ëª… ì—†ì´ ìš”ì•½ë§Œ:

ì¢…ëª©: {name}({ticker}) ìˆ˜ìµë¥ : {profit_rate:+.1f}% ì²­ì‚°: {close_reason}
ë§¤ìˆ˜ìƒí™©: {buy_ctx} / ë§¤ë„ìƒí™©: {sell_ctx}
ë§¤ìˆ˜íŒë‹¨: {buy_q} / ë§¤ë„íŒë‹¨: {sell_q}
í•µì‹¬êµí›ˆ: {lesson_str}
í•œì¤„ìš”ì•½: {one_line_summary}

ìš”ì•½:"""

    try:
        from utils.ai_client import call_ai
        result = call_ai(_CLIENT, prompt, max_tokens=100, temperature=0.1,
                         caller="memory_compressor").strip()
        # ë§ˆí¬ë‹¤ìš´Â·ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
        result = re.sub(r"^(ìš”ì•½:?\s*|Summary:?\s*)", "", result, flags=re.IGNORECASE)
        result = result[:100]  # ìµœëŒ€ 100ì
        return result
    except Exception as e:
        logger.debug(f"[compressor] AI ìš”ì•½ ì‹¤íŒ¨ ({ticker}): {e}")
        return ""


def _rule_based_summary(
    profit_rate: float,
    close_reason: str,
    raw_lessons: str,
    one_line_summary: str,
) -> str:
    """
    AI ì—†ì„ ë•Œ rule-based ìš”ì•½ ìƒì„±.
    one_line_summaryê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©, ì—†ìœ¼ë©´ ìˆ˜ìµë¥ +ì²­ì‚°ì‚¬ìœ  ì¡°í•©.
    """
    if one_line_summary:
        return one_line_summary[:80]

    reason_map = {
        "take_profit_1": "1ì°¨ìµì ˆ",
        "take_profit_2": "2ì°¨ìµì ˆ",
        "stop_loss":     "ì†ì ˆ",
        "trailing_stop": "íŠ¸ë ˆì¼ë§ìŠ¤íƒ‘",
        "force_close":   "ê°•ì œì²­ì‚°",
        "final_close":   "ìµœì¢…ì²­ì‚°",
    }
    reason_kr = reason_map.get(close_reason, close_reason or "ì²­ì‚°")

    lesson_short = ""
    try:
        lessons = json.loads(raw_lessons or "[]")
        if lessons and isinstance(lessons[0], dict):
            lesson_short = lessons[0].get("action", "")[:30]
    except Exception:
        pass

    base = f"{profit_rate:+.1f}% {reason_kr}"
    return f"{base} | {lesson_short}" if lesson_short else base
