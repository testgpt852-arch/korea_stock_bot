"""
korea_stock_bot â€” ì™¸ë¶€ ë°ì´í„° ì†ŒìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸ (í•µì‹¬ 3ê°œ)
===========================================================
í…ŒìŠ¤íŠ¸ ëŒ€ìƒ: DART ê³µì‹œ / GDELT ì˜ë¬¸ ë‰´ìŠ¤ / RSS í”¼ë“œ

[ì‹¤í–‰]
    python test_data_sources.py
"""

import os, sys, time, json
from pathlib import Path
from datetime import datetime, timedelta

# â”€â”€â”€ .env ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from dotenv import load_dotenv

_env_path = os.environ.get("ENV_PATH")
if _env_path:
    load_dotenv(dotenv_path=_env_path)
else:
    for _candidate in [Path(__file__).parent / ".env",
                        Path(__file__).parent.parent / ".env",
                        Path.cwd() / ".env"]:
        if _candidate.exists():
            load_dotenv(dotenv_path=str(_candidate))
            break
    else:
        load_dotenv()

# â”€â”€â”€ ê²°ê³¼ ì§‘ê³„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
results = []

def ok(name, detail=""):
    results.append(("âœ… PASS", name, detail))
    print(f"  âœ… PASS  {name}" + (f"  â†’  {detail}" if detail else ""))

def fail(name, detail=""):
    results.append(("âŒ FAIL", name, detail))
    print(f"  âŒ FAIL  {name}" + (f"  â†’  {detail}" if detail else ""))

def skip(name, reason=""):
    results.append(("â­  SKIP", name, reason))
    print(f"  â­  SKIP  {name}" + (f"  ({reason})" if reason else ""))

def section(title, description=""):
    print(f"\n{'='*62}")
    print(f"  {title}")
    if description:
        print(f"  ğŸ’¬ {description}")
    print(f"{'='*62}")

# â”€â”€â”€ í™˜ê²½ë³€ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DART_API_KEY = os.environ.get("DART_API_KEY")
NEWSAPI_KEY  = os.environ.get("NEWSAPI_ORG_KEY") or os.environ.get("GOOGLE_NEWS_API_KEY", "")

TODAY     = datetime.today().strftime("%Y%m%d")
TODAY_KR  = datetime.today().strftime("%Y-%m-%d")

print(f"\n{'='*62}")
print("  ğŸ”‘ í™˜ê²½ë³€ìˆ˜ í˜„í™©")
print(f"{'='*62}")
for _var, _val, _desc in [
    ("DART_API_KEY",   DART_API_KEY, "ê¸ˆìœµê°ë…ì› ê³µì‹œ"),
    ("NEWSAPI_ORG_KEY", NEWSAPI_KEY, "ì˜ë¬¸ ë‰´ìŠ¤ (ë³´ì¡°)"),
]:
    _st = "âœ… ìˆìŒ" if _val else "âŒ ì—†ìŒ"
    _mk = ("*"*(len(_val)-4)+_val[-4:]) if _val and len(_val)>4 else ("-" if not _val else "ì„¤ì •ë¨")
    print(f"  {_st}  {_var:<26} ({_desc})  {_mk}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  1. DART API â€” ê³µì‹œ / ì´ë²¤íŠ¸ ìº˜ë¦°ë”
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
section("1. DART API  (ê³µì‹œÂ·IRÂ·ì£¼ì£¼ì´íšŒÂ·ì‹¤ì )",
        "ê¸ˆìœµê°ë…ì› OpenDART. ìˆ˜ì£¼/ë°°ë‹¹/ìì‚¬ì£¼ ë“± ì£¼ê°€ì— ì˜í–¥ ì£¼ëŠ” ê³µì‹œë¥¼ ìˆ˜ì§‘.")

if not DART_API_KEY:
    skip("DART API ì „ì²´", "DART_API_KEY í™˜ê²½ë³€ìˆ˜ ë¯¸ì„¤ì •")
else:
    import requests

    # 1-1. ê³µì‹œëª©ë¡ API (ìµœê·¼ 5ì¼)
    try:
        bgn_5d = (datetime.today() - timedelta(days=5)).strftime("%Y%m%d")
        r = requests.get("https://opendart.fss.or.kr/api/list.json", params={
            "crtfc_key":  DART_API_KEY,
            "bgn_de":     bgn_5d,
            "end_de":     TODAY,
            "page_count": 10,
        }, timeout=10)
        data = r.json()
        if data.get("status") == "000":
            ok("DART ê³µì‹œëª©ë¡ API", f"ìµœê·¼5ì¼={data.get('total_count',0)}ê±´")
        else:
            fail("DART ê³µì‹œëª©ë¡ API", f"status={data.get('status')} msg={data.get('message')}")
    except Exception as e:
        fail("DART ê³µì‹œëª©ë¡ API", str(e))

    # 1-2. ì´ë²¤íŠ¸ ìº˜ë¦°ë”
    # â”€â”€ ì™œ ì´ë²¤íŠ¸ 0ê±´ì´ ë‚˜ì™”ëŠ”ê°€? â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # DART list.json ì€ ê³µì‹œ "ì ‘ìˆ˜ì¼" ê¸°ì¤€ìœ¼ë¡œ ê²€ìƒ‰í•œë‹¤.
    # ê¸°ì¡´ ì½”ë“œì—ì„œ bgn_de=TODAY (ì˜¤ëŠ˜=ì£¼ë§) ë¡œ ì„¤ì •í•´ì„œ
    # "ì˜¤ëŠ˜ ì´í›„ ì ‘ìˆ˜ëœ ê³µì‹œ"ë¥¼ ì¡°íšŒí–ˆëŠ”ë° â†’ ì£¼ë§ì—” ê³µì‹œ ìì²´ê°€ ì—†ì–´ì„œ 4ê±´ ë¿
    # ê·¸ 4ê±´ë„ ì£¼ì£¼ì´íšŒÂ·IR í‚¤ì›Œë“œê°€ ì—†ëŠ” ì¼ë°˜ ê³µì‹œë¼ ì´ë²¤íŠ¸ 0ê±´ìœ¼ë¡œ ë‚˜ì˜¨ ê²ƒ.
    #
    # âœ… ìˆ˜ì •: bgn_deë¥¼ ê³¼ê±° 30ì¼ë¡œ ì„¤ì •
    #   â†’ "ìµœê·¼ 30ì¼ ë‚´ ì ‘ìˆ˜ëœ ì´ë²¤íŠ¸ ê´€ë ¨ ê³µì‹œ" ì¡°íšŒ
    #   â†’ ì£¼ì£¼ì´íšŒÂ·IR ê³µì‹œëŠ” ë³´í†µ ìˆ˜ ì£¼ ì „ì— ë¯¸ë¦¬ ì ‘ìˆ˜ë¨
    #   â†’ ì´ ë°©ì‹ì´ ì‹¤ì œ event_calendar_collector.py ì˜ ë™ì‘ ë°©ì‹ê³¼ ë™ì¼
    try:
        bgn_30d = (datetime.today() - timedelta(days=30)).strftime("%Y%m%d")
        r2 = requests.get("https://opendart.fss.or.kr/api/list.json", params={
            "crtfc_key":  DART_API_KEY,
            "bgn_de":     bgn_30d,   # ê³¼ê±° 30ì¼ â€” ì ‘ìˆ˜ëœ ì´ë²¤íŠ¸ ê³µì‹œ í™•ì¸
            "end_de":     TODAY,
            "page_count": 100,
            "sort":       "date",
            "sort_mthd":  "desc",
        }, timeout=10)
        data2 = r2.json()
        status2 = data2.get("status", "")

        if status2 == "000":
            _EVENT_KW = [
                "ê¸°ì—…ì„¤ëª…íšŒ", "IR ", "NDR", "ê¸°ì—…íƒë°©",
                "ì£¼ì£¼ì´íšŒ", "ì„ì‹œì£¼ì£¼ì´íšŒ", "ì •ê¸°ì£¼ì£¼ì´íšŒ",
                "ì‹¤ì ë°œí‘œ", "ì˜ì—…ì‹¤ì ", "ì ì •ì‹¤ì ", "ë¶„ê¸°ì‹¤ì ",
                "í˜„ê¸ˆë°°ë‹¹", "ì¤‘ê°„ë°°ë‹¹", "íŠ¹ë³„ë°°ë‹¹", "ë°°ë‹¹ê²°ì •",
            ]
            all_items = data2.get("list", [])
            events = [
                item for item in all_items
                if any(kw in item.get("report_nm", "") for kw in _EVENT_KW)
            ]

            if events:
                _sample = " | ".join(
                    f"{e.get('corp_name','')} [{e.get('report_nm','')[:14]}]"
                    for e in events[:3]
                )
                ok("DART ì´ë²¤íŠ¸ìº˜ë¦°ë” (ìµœê·¼30ì¼)",
                   f"ì´ë²¤íŠ¸ê³µì‹œ={len(events)}ê±´  ì˜ˆì‹œ={_sample}")
            else:
                # ì´ë²¤íŠ¸ ê³µì‹œê°€ ì§„ì§œ ì—†ìœ¼ë©´ â€” ì „ì²´ ê³µì‹œ ìƒ˜í”Œ ì¶œë ¥í•´ì„œ í™•ì¸ ê°€ëŠ¥í•˜ê²Œ
                _all_sample = " | ".join(
                    f"[{i.get('report_nm','')[:12]}]" for i in all_items[:5]
                )
                fail("DART ì´ë²¤íŠ¸ìº˜ë¦°ë” (ìµœê·¼30ì¼)",
                     f"ì´ë²¤íŠ¸ í‚¤ì›Œë“œ ë§¤ì¹­ 0ê±´ (ì „ì²´={data2.get('total_count',0)}ê±´)  "
                     f"ê³µì‹œìƒ˜í”Œ={_all_sample}")

        elif status2 == "013":
            ok("DART ì´ë²¤íŠ¸ìº˜ë¦°ë”", "ì¡°íšŒ ë°ì´í„° ì—†ìŒ (013 ì •ìƒ)")
        else:
            fail("DART ì´ë²¤íŠ¸ìº˜ë¦°ë”", f"status={status2} msg={data2.get('message')}")
    except Exception as e:
        fail("DART ì´ë²¤íŠ¸ìº˜ë¦°ë”", str(e))


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  2. GDELT + NewsAPI â€” ì§€ì •í•™Â·ê¸€ë¡œë²Œ ì˜ë¬¸ ë‰´ìŠ¤
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  GDELT: ì™„ì „ë¬´ë£Œ, APIí‚¤ ë¶ˆí•„ìš”, 15ë¶„ ë‹¨ìœ„ ì—…ë°ì´íŠ¸
#  ì£¼ì˜: ë™ì¼ IP ì—°ì† ìš”ì²­ ì‹œ ë¹ˆ body(rate limit) ë°˜í™˜
#        â†’ ë‹¨ì¼ í†µí•©ì¿¼ë¦¬ë¡œ 1íšŒë§Œ í˜¸ì¶œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
section("2. GDELT + NewsAPI  (ì§€ì •í•™Â·ê¸€ë¡œë²Œ ì˜ë¬¸ ë‰´ìŠ¤)",
        "GDELT=ì™„ì „ë¬´ë£ŒÂ·APIí‚¤ë¶ˆí•„ìš”. ê´€ì„¸/ë°©ì‚°/ë°˜ë„ì²´ ë“± ì§€ì •í•™ ì´ë²¤íŠ¸ ì‹¤ì‹œê°„ ê°ì§€.")

import requests as _req2

# â”€â”€ 2-1. GDELT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_GDELT_BASE = "https://api.gdeltproject.org/api/v2/doc/doc"

def _gdelt_freshness(seendate_str: str) -> str:
    try:
        from datetime import timezone
        dt = datetime.strptime(seendate_str[:14], "%Y%m%d%H%M%S")
        dt = dt.replace(tzinfo=timezone.utc)
        h = (datetime.now(timezone.utc) - dt).total_seconds() / 3600
        return f"{int(h*60)}ë¶„ ì „" if h < 1 else (f"ì•½ {int(h)}ì‹œê°„ ì „" if h < 24 else f"ì•½ {int(h/24)}ì¼ ì „")
    except Exception:
        return seendate_str[:10] if seendate_str else "?"

_GDELT_QUERY = (
    '"South Korea" OR "KOSPI" OR "Korea tariff" OR '
    '"Korea defense" OR "Korea semiconductor" OR "Korea trade"'
)

try:
    _gr = _req2.get(_GDELT_BASE, params={
        "query":      _GDELT_QUERY,
        "mode":       "artlist",
        "maxrecords": 10,
        "timespan":   "3d",
        "sort":       "DateDesc",
        "format":     "json",
        "sourcelang": "english",
    }, timeout=25)

    # â”€â”€ ì‘ë‹µ ê²€ì¦ (rate limit ì‹œ ë¹ˆ body ë˜ëŠ” HTML ì—ëŸ¬ í˜ì´ì§€ ë°˜í™˜) â”€â”€
    _raw_text = _gr.text.strip() if _gr.text else ""
    _is_json  = _raw_text.startswith("{") or _raw_text.startswith("[")

    if not _raw_text:
        fail("GDELT ì—°ê²° í…ŒìŠ¤íŠ¸",
             "ë¹ˆ ì‘ë‹µ â€” rate limit. ì ì‹œ í›„ ë‹¨ë… ì‹¤í–‰ ì‹œ ì •ìƒ ë™ì‘í•¨. "
             "ë´‡ ì‹¤ìš´ì˜(30ë¶„ ê°„ê²©)ì—ì„œëŠ” rate limit ì—†ìŒ")
    elif not _is_json:
        fail("GDELT ì—°ê²° í…ŒìŠ¤íŠ¸",
             f"JSON ì•„ë‹Œ ì‘ë‹µ ë°˜í™˜ (HTML ì—ëŸ¬ ë“±) â€” ì²« 50ì: {_raw_text[:50]}")
    else:
        _gdata = _gr.json()
        _garts = _gdata.get("articles", [])
        if _garts:
            _fresh = _gdelt_freshness(_garts[0].get("seendate", ""))
            _dom   = _garts[0].get("domain", "?")
            _title = (_garts[0].get("title") or "")[:45]
            ok("GDELT ì—°ê²° í…ŒìŠ¤íŠ¸ (í•œêµ­ ê´€ë ¨ í†µí•©ì¿¼ë¦¬)",
               f"ê¸°ì‚¬ìˆ˜={len(_garts)}ê±´  ìµœì‹ ê¸°ì‚¬={_fresh}  ì†ŒìŠ¤={_dom}: {_title}")

            # ìµœì‹ ì„± ê²€ì¦: 24ì‹œê°„ ì´ë‚´ ê¸°ì‚¬ ë¹„ìœ¨
            from datetime import timezone as _tz
            _fresh_cnt = sum(
                1 for a in _garts
                if (lambda sd: (
                    (datetime.now(_tz.utc) - datetime.strptime(sd[:14], "%Y%m%d%H%M%S")
                     .replace(tzinfo=_tz.utc)).total_seconds() / 3600 <= 24
                ) if sd else False)(a.get("seendate", ""))
            )
            if _fresh_cnt > 0:
                ok("GDELT ìµœì‹ ì„±", f"24ì‹œê°„ ì´ë‚´ ê¸°ì‚¬ {_fresh_cnt}/{len(_garts)}ê±´ â€” ì‹¤ì‹œê°„ ìˆ˜ì§‘ ì •ìƒ")
            else:
                fail("GDELT ìµœì‹ ì„±",
                     f"24ì‹œê°„ ì´ë‚´ ê¸°ì‚¬ 0ê±´ (ê°€ì¥ ìµœê·¼: {_fresh}) â€” ì¿¼ë¦¬ ë˜ëŠ” ì„œë²„ ìƒíƒœ í™•ì¸")
        else:
            fail("GDELT ì—°ê²° í…ŒìŠ¤íŠ¸", "ê¸°ì‚¬ 0ê±´ (ì‘ë‹µì€ ì •ìƒ JSON)")

except Exception as _ge:
    fail("GDELT ì—°ê²° í…ŒìŠ¤íŠ¸", str(_ge))

# â”€â”€ 2-2. NewsAPI top-headlines (ë³´ì¡°) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not NEWSAPI_KEY:
    skip("NewsAPI top-headlines (ë³´ì¡°)", "NEWSAPI_ORG_KEY ë¯¸ì„¤ì • â€” GDELT ë‹¨ë… ìš´ìš©")
else:
    try:
        _rn = _req2.get("https://newsapi.org/v2/top-headlines",
                        params={"apiKey": NEWSAPI_KEY, "category": "business",
                                "language": "en", "pageSize": 5}, timeout=10)
        _dn = _rn.json()
        if _dn.get("status") == "ok":
            ok("NewsAPI top-headlines (ë³´ì¡°)", f"ì´={_dn.get('totalResults',0)}ê±´")
        elif _dn.get("code") == "rateLimited":
            fail("NewsAPI top-headlines", "Rate Limit â€” ë¬´ë£Œ 100req/day ì´ˆê³¼")
        else:
            fail("NewsAPI top-headlines", _dn.get("message", "")[:60])
    except Exception as _ne:
        fail("NewsAPI top-headlines", str(_ne))


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  3. RSS í”¼ë“œ â€” BBC / FT / Google News / korea.kr
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
section("3. RSS í”¼ë“œ  (BBCÂ·FTÂ·Google NewsÂ·Korea.kr)",
        "ë¬´ë£Œ. ì§€ì •í•™ ë‰´ìŠ¤ + Korea.kr ì •ì±…ë¸Œë¦¬í•‘ìœ¼ë¡œ ì •ë¶€ ë°œí‘œ ì‹¤ì‹œê°„ ìˆ˜ì§‘.")

try:
    import feedparser
    import requests as _rss_req
    import urllib.parse
    import email.utils as _eu
    from datetime import timezone as _tzr

    def _rss_freshness(entry) -> str:
        """RSS entry published â†’ 'ì•½ Nì‹œê°„ ì „'"""
        for field in ("published", "updated"):
            val = entry.get(field, "")
            if not val:
                continue
            try:
                parsed = _eu.parsedate(val)
                if parsed:
                    dt = datetime(*parsed[:6], tzinfo=_tzr.utc)
                    h = (datetime.now(_tzr.utc) - dt).total_seconds() / 3600
                    if h < 1:   return f"{int(h*60)}ë¶„ ì „"
                    if h < 24:  return f"ì•½ {int(h)}ì‹œê°„ ì „"
                    return f"ì•½ {int(h/24)}ì¼ ì „"
            except Exception:
                pass
        return "ì‹œê°ë¯¸ìƒ"

    # â”€â”€ 3-1. í‘œì¤€ RSS (feedparser ì§ì ‘ íŒŒì‹±) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    _SIMPLE_RSS = [
        ("BBC Business",      "https://feeds.bbci.co.uk/news/business/rss.xml"),
        ("BBC World",         "https://feeds.bbci.co.uk/news/world/rss.xml"),
        ("Google News KRê²½ì œ", "https://news.google.com/rss/search?"
                               "q=Korea+economy+stock&hl=en&gl=KR&ceid=KR:en"),
        ("Google News ë°©ì‚°",  "https://news.google.com/rss/search?"
                               + urllib.parse.urlencode({
                                   "q":"í•œêµ­ ë°©ì‚° ìˆ˜ì¶œ", "hl":"ko",
                                   "gl":"KR", "ceid":"KR:ko"})),
    ]
    for _name, _url in _SIMPLE_RSS:
        try:
            _feed = feedparser.parse(_url)
            if _feed.entries:
                _e0 = _feed.entries[0]
                ok(f"RSS {_name}",
                   f"ê¸°ì‚¬ìˆ˜={len(_feed.entries)}ê±´  ìµœì‹ ={_rss_freshness(_e0)}"
                   f"  ì œëª©={_e0.get('title','')[:30]}")
            elif _feed.bozo:
                fail(f"RSS {_name}", f"íŒŒì‹±ì˜¤ë¥˜: {_feed.bozo_exception}")
            else:
                fail(f"RSS {_name}", "entries ì—†ìŒ")
        except Exception as e:
            fail(f"RSS {_name}", str(e))
        time.sleep(0.4)

    # â”€â”€ 3-2. requests ì„ fetch ì†ŒìŠ¤ (SSL ìš°íšŒ / ë¹„í‘œì¤€ ì¸ì½”ë”©) â”€â”€
    _FETCH_RSS = [
        # FT: Windows í™˜ê²½ SSL ì¸ì¦ì„œ ì˜¤ë¥˜ â†’ verify=False
        ("FT Markets", "https://www.ft.com/markets?format=rss", False),
    ]
    for _name, _url, _verify in _FETCH_RSS:
        try:
            _hdrs = {"User-Agent": "Mozilla/5.0 (compatible; KoreaStockBot/1.0)"}
            _resp = _rss_req.get(_url, headers=_hdrs, timeout=10, verify=_verify)
            _resp.raise_for_status()
            _feed = feedparser.parse(_resp.content)
            if _feed.entries:
                _e0 = _feed.entries[0]
                ok(f"RSS {_name}",
                   f"ê¸°ì‚¬ìˆ˜={len(_feed.entries)}ê±´  ìµœì‹ ={_rss_freshness(_e0)}"
                   f"  ì œëª©={_e0.get('title','')[:30]}")
            elif _feed.bozo:
                fail(f"RSS {_name}", f"íŒŒì‹±ì˜¤ë¥˜: {str(_feed.bozo_exception)[:60]}")
            else:
                fail(f"RSS {_name}", "entries ì—†ìŒ")
        except Exception as e:
            fail(f"RSS {_name}", str(e))
        time.sleep(0.4)

    # â”€â”€ 3-3. í•œêµ­ ì •ë¶€ RSS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ê¸°ì¬ë¶€(moef.go.kr): ì„œë²„ê°€ ê¹¨ì§„ XML ë°˜í™˜ â†’ ìˆ˜ì • ë¶ˆê°€, skip
    # ë°©ì‚¬ì²­(dapa.go.kr): 404 ì„œë¹„ìŠ¤ íì§€ â†’ skip
    skip("RSS ê¸°ì¬ë¶€ (moef.go.kr)", "ì„œë²„ê°€ ê¹¨ì§„ XML ë°˜í™˜ â€” ì„œë²„ ì¸¡ ë¬¸ì œë¡œ ìˆ˜ì • ë¶ˆê°€")
    skip("RSS ë°©ì‚¬ì²­ (dapa.go.kr)", "404 â€” ì„œë¹„ìŠ¤ íì§€ë¨")

    # â”€â”€ korea.kr ì •ì±…ë¸Œë¦¬í•‘ RSS (ì •ë¶€ í†µí•© ë³´ë„ìë£Œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ê¸°ì¬ë¶€Â·í–‰ì•ˆë¶€Â·ê³¼ê¸°ë¶€ ë“± ì „ ë¶€ì²˜ í†µí•©
    # ë¹„í‘œì¤€ XML: invalid token í¬í•¨ â†’ bozoì—¬ë„ entriesê°€ ìˆìœ¼ë©´ ìˆ˜ì§‘ ê°€ëŠ¥
    _KR_GOV_HEADERS = {
        "User-Agent": "Mozilla/5.0 (compatible; KoreaStockBot/1.0)",
        "Accept":     "application/rss+xml, text/xml, */*",
        "Referer":    "https://www.korea.kr/",
    }
    try:
        _kr = _rss_req.get("https://www.korea.kr/rss/policyNewsAll.do",
                           headers=_KR_GOV_HEADERS, timeout=12)
        _kr.raise_for_status()

        # â”€â”€ XML ì „ì²˜ë¦¬: invalid token ì œê±° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ì˜¤ë¥˜ ìœ„ì¹˜(line 290, col 30)ì— HTML ì—”í‹°í‹°(&nbsp; ë“±) ë˜ëŠ”
        # ì œì–´ë¬¸ìê°€ í¬í•¨ë¼ ìˆì–´ íŒŒì‹± ì‹¤íŒ¨
        # ì „ëµ: EUC-KR ë””ì½”ë”© â†’ ì œì–´ë¬¸ì ì œê±° â†’ UTF-8 ì¬ì¸ì½”ë”©
        import re as _re
        _raw_bytes  = _kr.content
        _ktext_raw  = _raw_bytes.decode("euc-kr", errors="replace")
        # 0x00~0x1F ë²”ìœ„ ì œì–´ë¬¸ì ì œê±° (íƒ­Â·ê°œí–‰Â·CR ì œì™¸)
        _ktext_clean = _re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f]', '', _ktext_raw)
        # &nbsp; â†’ ê³µë°±, &amp; ì¤‘ë³µ â†’ &amp;
        _ktext_clean = _ktext_clean.replace("&nbsp;", " ").replace("&copy;", "Â©")
        _kfeed = feedparser.parse(_ktext_clean.encode("utf-8"))

        if _kfeed.entries:
            _ke0   = _kfeed.entries[0]
            _ktitle = _ke0.get("title", "")[:35]
            _kfresh = _rss_freshness(_ke0)
            ok("RSS korea.kr ì •ì±…ë¸Œë¦¬í•‘ (ê¸°ì¬ë¶€ ëŒ€ì²´)",
               f"ê¸°ì‚¬ìˆ˜={len(_kfeed.entries)}ê±´  ìµœì‹ ={_kfresh}  ì œëª©={_ktitle}")
        elif _kfeed.bozo:
            # bozoì§€ë§Œ partial entries ìˆì„ ìˆ˜ ìˆìŒ â€” ì‹¤ì œ ë´‡ ì½”ë“œëŠ” entries ìˆìœ¼ë©´ ìˆ˜ì§‘í•¨
            fail("RSS korea.kr ì •ì±…ë¸Œë¦¬í•‘",
                 f"XML ë¹„í‘œì¤€ íŒŒì‹±ì‹¤íŒ¨: {str(_kfeed.bozo_exception)[:60]}\n"
                 "       â„¹ï¸  geopolitics_collector.pyëŠ” bozoì—¬ë„ entries ìˆìœ¼ë©´ ìˆ˜ì§‘í•˜ë¯€ë¡œ\n"
                 "            ì‹¤ì œ ë´‡ ìš´ì˜ì—ëŠ” ì˜í–¥ ì—†ì„ ìˆ˜ ìˆìŒ. ë³„ë„ í™•ì¸ ê¶Œì¥")
        else:
            fail("RSS korea.kr ì •ì±…ë¸Œë¦¬í•‘", "entries ì—†ìŒ")
    except Exception as _ke:
        fail("RSS korea.kr ì •ì±…ë¸Œë¦¬í•‘", str(_ke))

except ImportError:
    skip("RSS í”¼ë“œ ì „ì²´", "pip install feedparser requests")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ğŸ“Š ê²°ê³¼ ìš”ì•½
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print(f"\n{'='*62}")
print("  ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
print(f"{'='*62}")

passed  = [r for r in results if r[0].startswith("âœ…")]
failed  = [r for r in results if r[0].startswith("âŒ")]
skipped = [r for r in results if r[0].startswith("â­")]

print(f"\n  ì´ {len(results)}ê°œ  |  âœ… ì„±ê³µ {len(passed)}  âŒ ì‹¤íŒ¨ {len(failed)}  â­ ìŠ¤í‚µ {len(skipped)}\n")

if failed:
    print("  â”€â”€ âŒ ì‹¤íŒ¨ í•­ëª© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    for _, name, detail in failed:
        print(f"  âŒ {name}")
        if detail:
            print(f"       â”” {detail}")

if skipped:
    print("\n  â”€â”€ â­ SKIP í•­ëª© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    for _, name, reason in skipped:
        print(f"  â­  {name}  ({reason})")

print(f"\n  {'ğŸ‰ ëª¨ë“  í•„ìˆ˜ í•­ëª© ì •ìƒ!' if not failed else 'âš ï¸  ì‹¤íŒ¨ í•­ëª©ì„ í™•ì¸í•˜ì„¸ìš”.'}\n")
