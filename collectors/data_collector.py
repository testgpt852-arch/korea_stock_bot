"""
collectors/data_collector.py
ë°ì´í„° ìˆ˜ì§‘ ì´ê´„ â€” ì›ì‹œ ë°ì´í„° ìˆ˜ì§‘Â·ìºì‹±Â·í…”ë ˆê·¸ë¨ ë°œì†¡ (v13.0 Step 4)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
[ì—­í• ]
  06:00 ë‹¨ì¼ ìŠ¤ì¼€ì¤„ë¡œ ëª¨ë“  ìˆ˜ì§‘ê¸°ë¥¼ asyncio.gather() ë³‘ë ¬ ì‹¤í–‰.
  ìˆ«ì ê¸°ì¤€ í•„í„°ë§ë§Œ ì ìš© (í•˜ë“œì½”ë”© í‚¤ì›Œë“œ ë§¤í•‘ ì „ë©´ ì œê±°).
  í•„í„°ë§ëœ ì›ì‹œ ë°ì´í„°ë¥¼ ì „ì—­ ìºì‹œì— ì €ì¥ í›„ í…”ë ˆê·¸ë¨ìœ¼ë¡œ ë°œì†¡.

[ë³‘ë ¬ ìˆ˜ì§‘ ëŒ€ìƒ â€” asyncio.gather()]
  â‘  filings            â€” DART ê³µì‹œ (ì „ë‚ , ë³¸ë¬¸ìš”ì•½ í¬í•¨)
  â‘¡ market_global      â€” ë¯¸êµ­ì¦ì‹œ + ì›ìì¬ (ì „ë‚ , Â±2%+ í•„í„°)
  â‘¢ news_naver         â€” ë„¤ì´ë²„ ë‰´ìŠ¤ (ë‹¹ì¼)
  â‘£ news_newsapi       â€” NewsAPI ê¸€ë¡œë²Œ ë‰´ìŠ¤ (ë‹¹ì¼)
  â‘¤ news_global_rss    â€” ê¸€ë¡œë²Œ RSS ë‰´ìŠ¤ (ì§€ì •í•™)
  â‘¥ price_domestic     â€” ì „ë‚  ê°€ê²©/ê¸°ê´€/ì™¸ì¸ ë°ì´í„° (ì‹œì´ 3000ì–µ ì´í•˜)
  â‘¦ sector_etf         â€” ì„¹í„° ETF ìê¸ˆíë¦„ (ì „ë‚ )
  â‘§ short_interest     â€” ê³µë§¤ë„ ì”ê³  (ì „ë‚ , ìƒìœ„ 20)
  â‘¨ event_calendar     â€” ê¸°ì—… ì´ë²¤íŠ¸ ìº˜ë¦°ë” (ë‹¹ì¼)
  â‘© closing_strength   â€” ë§ˆê°ê°•ë„ (ì „ë‚ , ìƒìœ„ 20)
  â‘ª volume_surge       â€” ê±°ë˜ëŸ‰ê¸‰ì¦ (ì „ë‚ , ìƒìœ„ 20)
  â‘« fund_concentration â€” ìê¸ˆì§‘ì¤‘ (ì „ë‚ , ìƒìœ„ 20)

[ìºì‹œ êµ¬ì¡° â€” get_cache()]
  {
    "collected_at":              str,          # KST ISO ìˆ˜ì§‘ ì‹œê°
    "dart_data":                 list[dict],   # ë³¸ë¬¸ìš”ì•½ í¬í•¨
    "market_data":               dict,         # Â±2%+ ì„¹í„°ETFë§Œ
    "news_naver":                dict,         # ìµœì‹  30ê±´
    "news_newsapi":              dict,         # ìµœì‹  20ê±´
    "news_global_rss":           list[dict],
    "price_data":                dict | None,  # ì‹œì´ 3000ì–µ ì´í•˜ í•„í„° ì ìš©
    "sector_etf_data":           list[dict],
    "short_data":                list[dict],   # ìƒìœ„ 20ì¢…ëª©
    "event_calendar":            list[dict],
    "closing_strength_result":   list[dict],   # ìƒìœ„ 20ì¢…ëª©
    "volume_surge_result":       list[dict],   # ìƒìœ„ 20ì¢…ëª©
    "fund_concentration_result": list[dict],   # ìƒìœ„ 20ì¢…ëª©
    "success_flags":             dict[str, bool],
  }

[ì ˆëŒ€ ê¸ˆì§€ â€” ARCHITECTURE ì¤€ìˆ˜]
  ì´ íŒŒì¼ì—ì„œ AI API í˜¸ì¶œ ê¸ˆì§€
  ì´ íŒŒì¼ì—ì„œ DB ê¸°ë¡ ê¸ˆì§€
  ìˆ˜ì§‘Â·ìºì‹±Â·ì›ì‹œë°ì´í„° ë°œì†¡ë§Œ ë‹´ë‹¹

[ì‚­ì œëœ í•¨ìˆ˜ â€” v13.0]
  _build_signals()         â€” í•˜ë“œì½”ë”© ë§¤í•‘ ê¸°ë°˜ ì‹ í˜¸ ìƒì„± ì „ë©´ ì‚­ì œ
  _compute_score_summary() â€” ë°ë“œì½”ë“œ, ì‚­ì œ
  _sig_us_market()         â€” í•˜ë“œì½”ë”© ë§¤í•‘ ì‚¬ìš©, ì‚­ì œ
  _sig_steel_etf()         â€” í•˜ë“œì½”ë”© ë§¤í•‘ ì‚¬ìš©, ì‚­ì œ
  _sig_sector_top()        â€” í•˜ë“œì½”ë”© ë§¤í•‘ ì‚¬ìš©, ì‚­ì œ
  _sig_geopolitics_from_rss() â€” ì‚­ì œ
  _sig_sector_flow()       â€” ì‚­ì œ
  _sig_datalab_trends()    â€” ì‚­ì œ
  _sig_prev_price()        â€” ì‚­ì œ
  _sig_dart_strength()     â€” ì‚­ì œ
  _sig_dart_to_theme()     â€” ì‚­ì œ
  _sig_event_impact()      â€” ì‚­ì œ

[ìˆ˜ì •ì´ë ¥]
  v12.0 Step 7: ì‹ ê·œ ìƒì„±
  v12.0 Step 8: signal_analyzer í¡ìˆ˜ â€” _build_signals() ì¶”ê°€
  v13.0 Step 4: _build_signals()Â·_compute_score_summary() ë° í•˜ìœ„ ì‹ í˜¸ í•¨ìˆ˜ ì „ë©´ ì‚­ì œ
                ìºì‹œ êµ¬ì¡° ë‹¨ìˆœí™” (signalsÂ·market_summary ë“± ì‚­ì œëœ í‚¤ ì œê±°)
                ì›ì‹œ ë°ì´í„° í…”ë ˆê·¸ë¨ ë°œì†¡ _send_raw_data_to_telegram() ì‹ ê·œ ì¶”ê°€
"""

import asyncio
from datetime import datetime, timezone, timedelta
from utils.logger import logger
from utils.date_utils import get_today, get_prev_trading_day, fmt_ymd
import config

KST = timezone(timedelta(hours=9))

# â”€â”€ ì „ì—­ ìºì‹œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_cache: dict = {}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PUBLIC API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def run() -> dict:
    """
    06:00 ìŠ¤ì¼€ì¤„ì—ì„œ í˜¸ì¶œ â€” ëª¨ë“  ìˆ˜ì§‘ê¸° ë³‘ë ¬ ì‹¤í–‰ í›„ ìºì‹œ ì €ì¥ ë° í…”ë ˆê·¸ë¨ ë°œì†¡.

    Returns:
        cache dict (get_cache()ì™€ ë™ì¼í•œ êµ¬ì¡°)
    """
    global _cache

    today = get_today()
    prev  = get_prev_trading_day(today)
    today_str = fmt_ymd(today)
    prev_str  = fmt_ymd(prev) if prev else None

    logger.info(f"[data_collector] ë³‘ë ¬ ìˆ˜ì§‘ ì‹œì‘ â€” ê¸°ì¤€ì¼: {prev_str or 'N/A'}")
    start_ts = datetime.now(KST)

    # â”€â”€ ë³‘ë ¬ ìˆ˜ì§‘ ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    (
        dart_data,
        market_data,
        naver_data,
        newsapi_data,
        global_rss_data,
        price_data,
        sector_etf_data,
        short_data,
        event_calendar_data,
        closing_strength_result,
        volume_surge_result,
        fund_concentration_result,
    ) = await asyncio.gather(
        _safe_collect("filings",            _collect_filings,           prev),
        _safe_collect("market_global",      _collect_market_global,     prev),
        _safe_collect("news_naver",         _collect_news_naver,        today),
        _safe_collect("news_newsapi",       _collect_news_newsapi,      today),
        _safe_collect("news_global_rss",    _collect_global_rss),
        _safe_collect("price_domestic",     _collect_price_domestic,    prev),
        _safe_collect("sector_etf",         _collect_sector_etf,        prev),
        _safe_collect("short_interest",     _collect_short_interest,    prev),
        _safe_collect("event_calendar",     _collect_event_calendar,    today),
        _safe_collect("closing_strength",   _collect_closing_strength,  prev_str),
        _safe_collect("volume_surge",       _collect_volume_surge,      prev_str),
        _safe_collect("fund_concentration", _collect_fund_concentration,prev_str),
    )

    elapsed = (datetime.now(KST) - start_ts).total_seconds()
    logger.info(f"[data_collector] ë³‘ë ¬ ìˆ˜ì§‘ ì™„ë£Œ â€” {elapsed:.1f}ì´ˆ")

    # â”€â”€ ê¸°ë³¸ê°’ ë³´ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    dart_data                 = dart_data                 or []
    market_data               = market_data               or {}
    naver_data                = naver_data                or {}
    newsapi_data              = newsapi_data              or {}
    global_rss_data           = global_rss_data           or []
    price_data                = price_data                or None
    sector_etf_data           = sector_etf_data           or []
    short_data                = short_data                or []
    event_calendar_data       = event_calendar_data       or []
    closing_strength_result   = closing_strength_result   or []
    volume_surge_result       = volume_surge_result       or []
    fund_concentration_result = fund_concentration_result or []

    # â”€â”€ ì„±ê³µ í”Œë˜ê·¸ ê¸°ë¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    success_flags = {
        "filings":            bool(dart_data),
        "market_global":      bool(market_data),
        "news_naver":         bool(naver_data),
        "news_newsapi":       bool(newsapi_data),
        "news_global_rss":    bool(global_rss_data),
        "price_domestic":     price_data is not None,
        "sector_etf":         bool(sector_etf_data),
        "short_interest":     bool(short_data),
        "event_calendar":     bool(event_calendar_data),
        "closing_strength":   bool(closing_strength_result),
        "volume_surge":       bool(volume_surge_result),
        "fund_concentration": bool(fund_concentration_result),
    }
    ok_count   = sum(success_flags.values())
    fail_count = len(success_flags) - ok_count
    logger.info(f"[data_collector] ìˆ˜ì§‘ ê²°ê³¼ â€” ì„±ê³µ:{ok_count} ì‹¤íŒ¨:{fail_count}")
    for name, ok in success_flags.items():
        if not ok:
            logger.warning(f"[data_collector]   âŒ {name} ìˆ˜ì§‘ ì‹¤íŒ¨ (ë¹„ì¹˜ëª…ì )")

    # â”€â”€ ìºì‹œ ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    _cache = {
        "collected_at":              datetime.now(KST).isoformat(),
        "dart_data":                 dart_data,
        "market_data":               market_data,
        "news_naver":                naver_data,
        "news_newsapi":              newsapi_data,
        "news_global_rss":           global_rss_data,
        "price_data":                price_data,
        "sector_etf_data":           sector_etf_data,
        "short_data":                short_data,
        "event_calendar":            event_calendar_data,
        "closing_strength_result":   closing_strength_result,
        "volume_surge_result":       volume_surge_result,
        "fund_concentration_result": fund_concentration_result,
        "success_flags":             success_flags,
    }

    logger.info("[data_collector] ìºì‹œ ì €ì¥ ì™„ë£Œ âœ…")

    # â”€â”€ ì›ì‹œ ë°ì´í„° í…”ë ˆê·¸ë¨ ë°œì†¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    try:
        _send_raw_data_to_telegram(_cache)
    except Exception as e:
        logger.warning(f"[data_collector] ì›ì‹œ ë°ì´í„° í…”ë ˆê·¸ë¨ ë°œì†¡ ì‹¤íŒ¨ (ë¹„ì¹˜ëª…ì ): {e}")

    return _cache


def get_cache() -> dict:
    """ì €ì¥ëœ ìºì‹œ ë°˜í™˜. run() ë¯¸í˜¸ì¶œ ì‹œ ë¹ˆ dict."""
    return _cache


def is_fresh(max_age_minutes: int = 180) -> bool:
    """
    ìºì‹œê°€ max_age_minutes ì´ë‚´ì— ìˆ˜ì§‘ëœ ê²½ìš° True.
    ê¸°ë³¸ 3ì‹œê°„ (06:00 ìˆ˜ì§‘ â†’ ì•„ì¹¨ë´‡ 08:30 ì‚¬ìš©: ì•½ 150ë¶„ ì°¨ì´).
    """
    if not _cache.get("collected_at"):
        return False
    try:
        collected = datetime.fromisoformat(_cache["collected_at"])
        age_min   = (datetime.now(KST) - collected).total_seconds() / 60
        return age_min <= max_age_minutes
    except Exception:
        return False


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ê°œë³„ ìˆ˜ì§‘ê¸° ë˜í¼ (ë™ê¸° â†’ asyncio executor)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def _safe_collect(name: str, fn, *args):
    """
    ë‹¨ì¼ ìˆ˜ì§‘ê¸° ì‹¤í–‰ â€” ì‹¤íŒ¨ ì‹œ None ë°˜í™˜ (ë¹„ì¹˜ëª…ì ).
    ëª¨ë“  ë™ê¸° ìˆ˜ì§‘ê¸°ë¥¼ executorì—ì„œ ì‹¤í–‰í•´ asyncio.gather()ì™€ í˜¸í™˜.
    """
    loop = asyncio.get_event_loop()
    try:
        result = await loop.run_in_executor(None, fn, *args)
        return result
    except Exception as e:
        logger.warning(f"[data_collector] {name} ìˆ˜ì§‘ ì‹¤íŒ¨ (ë¹„ì¹˜ëª…ì ): {e}")
        return None


def _collect_filings(target_date):
    if target_date is None:
        return []
    from collectors.filings import collect
    return collect(target_date)


def _collect_market_global(target_date):
    if target_date is None:
        return {}
    from collectors.market_global import collect
    return collect(target_date)


def _collect_news_naver(target_date):
    from collectors.news_naver import collect
    return collect(target_date)


def _collect_news_newsapi(target_date):
    from collectors.news_newsapi import collect
    return collect(target_date)


def _collect_global_rss():
    if not config.GEOPOLITICS_ENABLED:
        return []
    from collectors.news_global_rss import collect
    return collect()


def _collect_price_domestic(target_date):
    if target_date is None:
        return None
    from collectors.price_domestic import collect_daily
    return collect_daily(target_date)


def _collect_sector_etf(target_date):
    if not config.SECTOR_ETF_ENABLED:
        return []
    if target_date is None:
        return []
    from collectors.sector_etf import collect
    return collect(target_date)


def _collect_short_interest(target_date):
    if not config.SHORT_INTEREST_ENABLED:
        return []
    if target_date is None:
        return []
    from collectors.short_interest import collect
    return collect(target_date)


def _collect_event_calendar(target_date):
    if not config.EVENT_CALENDAR_ENABLED:
        return []
    from collectors.event_calendar import collect
    return collect(target_date)


def _collect_closing_strength(date_str: str | None):
    """ë§ˆê°ê°•ë„ â€” closing_strength.analyze()"""
    if not date_str:
        return []
    from collectors.closing_strength import analyze
    return analyze(date_str)


def _collect_volume_surge(date_str: str | None):
    """ê±°ë˜ëŸ‰ê¸‰ì¦ â€” volume_surge.analyze()"""
    if not date_str:
        return []
    from collectors.volume_surge import analyze
    return analyze(date_str)


def _collect_fund_concentration(date_str: str | None):
    """ìê¸ˆì§‘ì¤‘ â€” fund_concentration.analyze()"""
    if not date_str:
        return []
    from collectors.fund_concentration import analyze
    return analyze(date_str)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì›ì‹œ ë°ì´í„° í…”ë ˆê·¸ë¨ ë°œì†¡ (Â§8)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _send_raw_data_to_telegram(cache: dict) -> None:
    """
    ìˆ˜ì§‘ ì™„ë£Œ ì§í›„ í•„í„°ë§ëœ ì›ì‹œ ë°ì´í„° ìš”ì•½ì„ í…”ë ˆê·¸ë¨ìœ¼ë¡œ ë°œì†¡.

    ëª©ì :
      - Gemini ì¥ì•  ì‹œ ì‚¬ìš©ìê°€ Claude ì±„íŒ…ì— ë¶™ì—¬ë„£ì–´ ìˆ˜ë™ ë¶„ì„ ê°€ëŠ¥
      - ì‚¬ìš©ì êµì°¨ê²€ì¦ìš© (ë´‡ì´ ì–´ë–¤ ë°ì´í„°ë¥¼ ë°›ì•˜ëŠ”ì§€ í™•ì¸)

    ë°œì†¡ í˜•ì‹ (Â§8 ì¤€ìˆ˜):
      ğŸ“Š [06:00 ìˆ˜ì§‘ ì™„ë£Œ] ì›ì‹œ ë°ì´í„° ìš”ì•½
      ğŸ‡ºğŸ‡¸ ë¯¸êµ­ ì„¹í„° (Â±2%+ í•„í„°)
      ğŸ“‹ DART ê³µì‹œ (ì˜¤ëŠ˜)
      ğŸ“ˆ ì „ë‚  ìƒí•œê°€/15%+
      ğŸ’° ìê¸ˆì§‘ì¤‘ ìƒìœ„ 5
      âš ï¸ Gemini ì¥ì•  ì‹œ ì´ ë©”ì‹œì§€ë¥¼ Claudeì—ê²Œ ì „ë‹¬í•˜ì„¸ìš”.
    """
    from telegram.sender import send as send_message  # [v13.0 ë²„ê·¸ìˆ˜ì •] send_message â†’ send (sender.pyì—ëŠ” send()ë§Œ ì¡´ì¬)

    lines: list[str] = []
    lines.append("ğŸ“Š [06:00 ìˆ˜ì§‘ ì™„ë£Œ] ì›ì‹œ ë°ì´í„° ìš”ì•½\n")

    # â”€â”€ ë¯¸êµ­ ì„¹í„° ETF (Â±2%+ í•„í„° ì ìš©ëœ ê²°ê³¼ë§Œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    market_data   = cache.get("market_data", {})
    us_market     = market_data.get("us_market", {})
    us_sectors    = us_market.get("sectors", {})
    commodities   = market_data.get("commodities", {})

    sector_lines = []
    for sector_name, sector_info in us_sectors.items():
        change = sector_info.get("change", "N/A")
        if change != "N/A":
            sector_lines.append(f"  - {sector_name}: {change}")

    lines.append("ğŸ‡ºğŸ‡¸ ë¯¸êµ­ ì„¹í„° (Â±2%+ í•„í„°)")
    if sector_lines:
        lines.extend(sector_lines)
    else:
        lines.append("  - í•´ë‹¹ ì—†ìŒ (Â±2% ì´ˆê³¼ ì„¹í„° ì—†ìŒ)")

    # ì›ìì¬
    commodity_lines = []
    for com_key, com_info in commodities.items():
        if not isinstance(com_info, dict):
            continue
        change = com_info.get("change", "N/A")
        if change and change != "N/A":
            commodity_lines.append(f"  - {com_key}: {change}")
    if commodity_lines:
        lines.append("\nğŸ›¢ ì›ìì¬")
        lines.extend(commodity_lines)

    # í™˜ìœ¨
    forex = market_data.get("forex", {})
    usd_krw = forex.get("USD/KRW", forex.get("usd_krw", "N/A"))
    if usd_krw != "N/A":
        lines.append(f"\nğŸ’± í™˜ìœ¨: USD/KRW {usd_krw}")

    # â”€â”€ DART ê³µì‹œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    dart_data = cache.get("dart_data", [])
    lines.append(f"\nğŸ“‹ DART ê³µì‹œ ({len(dart_data)}ê±´)")
    if dart_data:
        for d in dart_data[:10]:                           # ìµœëŒ€ 10ê±´
            name      = d.get("ì¢…ëª©ëª…",  "")
            kind      = d.get("ê³µì‹œì¢…ë¥˜", "")
            size      = d.get("ê·œëª¨",    "")
            summary   = d.get("ë³¸ë¬¸ìš”ì•½", "")
            cap       = d.get("ì‹œê°€ì´ì•¡", 0)
            cap_str   = f" ì‹œì´{cap // 100_000_000}ì–µ" if cap else ""
            detail    = summary or size
            lines.append(f"  - {name}: {kind} {detail}{cap_str}".rstrip())
    else:
        lines.append("  - í•´ë‹¹ ì—†ìŒ")

    # â”€â”€ ì „ë‚  ìƒí•œê°€/15%+ ê¸‰ë“± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    price_data  = cache.get("price_data") or {}
    upper_limit = price_data.get("upper_limit", [])
    top_gainers = price_data.get("top_gainers", [])

    lines.append(f"\nğŸ“ˆ ì „ë‚  ìƒí•œê°€/15%+")
    all_movers = sorted(
        upper_limit + top_gainers,
        key=lambda x: x.get("ë“±ë½ë¥ ", 0),
        reverse=True,
    )
    if all_movers:
        for s in all_movers[:10]:
            name    = s.get("ì¢…ëª©ëª…", "")
            rate    = s.get("ë“±ë½ë¥ ", 0)
            cap     = s.get("ì‹œê°€ì´ì•¡", 0)
            cap_str = f" ì‹œì´{cap // 100_000_000}ì–µ" if cap else ""
            lines.append(f"  - {name}: {rate:+.1f}%{cap_str}")
    else:
        lines.append("  - í•´ë‹¹ ì—†ìŒ")

    # â”€â”€ ìê¸ˆì§‘ì¤‘ ìƒìœ„ 5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    fund_top = cache.get("fund_concentration_result", [])
    lines.append(f"\nğŸ’° ìê¸ˆì§‘ì¤‘ ìƒìœ„ 5 (ê±°ë˜ëŒ€ê¸ˆ/ì‹œì´ ë¹„ìœ¨)")
    if fund_top:
        for f in fund_top[:5]:
            name  = f.get("ì¢…ëª©ëª…", f.get("name", ""))
            ratio = f.get("ratio", f.get("ê±°ë˜ëŒ€ê¸ˆì‹œì´ë¹„ìœ¨", 0))
            lines.append(f"  - {name}: {ratio:.1f}%" if ratio else f"  - {name}")
    else:
        lines.append("  - í•´ë‹¹ ì—†ìŒ")

    # â”€â”€ ê³µë§¤ë„ ìƒìœ„ 5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    short_top = cache.get("short_data", [])
    lines.append(f"\nğŸ©³ ê³µë§¤ë„ ìƒìœ„ 5")
    if short_top:
        for s in short_top[:5]:
            name   = s.get("ì¢…ëª©ëª…", s.get("name", ""))
            ratio  = s.get("short_ratio", s.get("ê³µë§¤ë„ë¹„ìœ¨", 0))
            lines.append(f"  - {name}: {ratio:.1f}%" if ratio else f"  - {name}")
    else:
        lines.append("  - í•´ë‹¹ ì—†ìŒ")

    # â”€â”€ ê±°ë˜ëŸ‰ ê¸‰ì¦ ìƒìœ„ 5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    volume_top = cache.get("volume_surge_result", [])
    lines.append(f"\nğŸ“Š ê±°ë˜ëŸ‰ ê¸‰ì¦ ìƒìœ„ 5 (ì „ì¼ ëŒ€ë¹„ 500%+)")
    if volume_top:
        for v in volume_top[:5]:
            name  = v.get("ì¢…ëª©ëª…", v.get("name", ""))
            surge = v.get("volume_ratio", v.get("ê±°ë˜ëŸ‰ë°°ìœ¨", 0))
            lines.append(f"  - {name}: {surge:.0f}x" if surge else f"  - {name}")
    else:
        lines.append("  - í•´ë‹¹ ì—†ìŒ")

    # â”€â”€ ì„±ê³µ í”Œë˜ê·¸ ìš”ì•½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    flags = cache.get("success_flags", {})
    failed = [k for k, v in flags.items() if not v]
    if failed:
        lines.append(f"\nâš ï¸ ìˆ˜ì§‘ ì‹¤íŒ¨: {', '.join(failed)}")

    lines.append("\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    lines.append("âš ï¸ Gemini ì¥ì•  ì‹œ ì´ ë©”ì‹œì§€ë¥¼ Claudeì—ê²Œ ì „ë‹¬í•˜ì„¸ìš”.")

    message = "\n".join(lines)

    try:
        send_message(message)
        logger.info("[data_collector] ì›ì‹œ ë°ì´í„° í…”ë ˆê·¸ë¨ ë°œì†¡ ì™„ë£Œ âœ…")
    except Exception as e:
        logger.warning(f"[data_collector] í…”ë ˆê·¸ë¨ send_message ì‹¤íŒ¨: {e}")
        raise
